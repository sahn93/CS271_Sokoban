{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c4ba328-3d89-4983-8c77-63527149aba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "#. #   #\n",
      "#  $   #\n",
      "#   # ##\n",
      "## # $.#\n",
      "#   $  #\n",
      "#  .# @#\n",
      "########\n"
     ]
    }
   ],
   "source": [
    "def read_file(path: str):\n",
    "    def parse_data(line: str) -> list[(int, int)]:\n",
    "        data = list(map(int, line.split()))\n",
    "        coordinates = []\n",
    "        for i in range(data[0]):\n",
    "            coordinates.append((data[i*2 + 1]-1, data[(i+1)*2]-1))\n",
    "        return coordinates\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        board_size = tuple(map(int, f.readline().split()))\n",
    "        walls = parse_data(f.readline())\n",
    "        boxes = parse_data(f.readline())\n",
    "        storages = parse_data(f.readline())\n",
    "        player = tuple(map(lambda x: int(x)-1, f.readline().split()))\n",
    "        \n",
    "    return board_size, walls, boxes, storages, player\n",
    "\n",
    "def visualize(data):\n",
    "    board_size, walls, boxes, storages, player = data\n",
    "    board = [[' '] * board_size[1] for _ in range(board_size[0])]\n",
    "    for r, c in walls:\n",
    "        board[r][c] = '#'\n",
    "    for r, c in boxes:\n",
    "        board[r][c] = '$'\n",
    "    for r, c in storages:\n",
    "        board[r][c] = '.'\n",
    "    board[player[0]][player[1]] = '@'\n",
    "    \n",
    "    for r in board:\n",
    "        print(''.join(r))\n",
    "    \n",
    "data = read_file('sokoban01.txt')\n",
    "visualize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "648a2d4c-917e-417a-98b9-04ec7bd314c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "class Reward:\n",
    "    STEP = -0.1\n",
    "    BOX_ON_STORAGE = 1.0\n",
    "    BOX_OFF_STORAGE = -1.0\n",
    "    ALL_ON_STORAGE = 10.0\n",
    "    DEADLOCK = -10.0\n",
    "    MOVE_TO_WALL = -1.0\n",
    "\n",
    "class Obj:\n",
    "    EMPTY = 0\n",
    "    STORAGE = 1\n",
    "    PLAYER = 2\n",
    "    PLAYER_ON_STORAGE = 3\n",
    "    WALL = 4\n",
    "    BOX = 5\n",
    "    BOX_ON_STORAGE = 6\n",
    "\n",
    "class QLearning:\n",
    "    def __init__(self, board_size, walls, boxes, storages, player, max_step, eps, eps_decay_rate):\n",
    "        self.Q = collections.defaultdict(lambda:np.zeros(4))\n",
    "        self.eps = eps\n",
    "        self.eps_decay_rate = eps_decay_rate\n",
    "        self.num_step = 0\n",
    "        self.max_step = max_step\n",
    "        self.board_size = board_size\n",
    "        self.walls = frozenset(walls)\n",
    "        self.storages = frozenset(storages)\n",
    "        self.state = (frozenset(boxes), player)\n",
    "        self.init_state = (frozenset(boxes), player)\n",
    "        self.board = [[0] * self.board_size[1] for _ in range(self.board_size[0])]\n",
    "        for box in boxes:\n",
    "            self.board[box[0]][box[1]] += Obj.BOX\n",
    "        self.board[player[0]][player[1]] += Obj.PLAYER\n",
    "        for wall in walls:\n",
    "            self.board[wall[0]][wall[1]] += Obj.WALL\n",
    "        for storage in storages:\n",
    "            self.board[storage[0]][storage[1]] += Obj.STORAGE\n",
    "        \n",
    "        self.move = {\n",
    "            0: (0, -1), # Left\n",
    "            1: (-1, 0), # Up\n",
    "            2: (0, 1),   # Right\n",
    "            3: (1, 0),  # Down\n",
    "        }\n",
    "        \n",
    "        self.direction = {\n",
    "            0: \"L\",\n",
    "            1: \"U\",\n",
    "            2: \"R\",\n",
    "            3: \"D\"\n",
    "        }\n",
    "        \n",
    "    def isDeadlock(self):\n",
    "        for box in self.state[0]:\n",
    "            if (self.board[box[0]][box[1]] != Obj.BOX_ON_STORAGE and\n",
    "                (self.board[box[0]+1][box[1]] == Obj.WALL and \n",
    "                self.board[box[0]][box[1]+1] == Obj.WALL or\n",
    "                self.board[box[0]][box[1]+1] == Obj.WALL and \n",
    "                self.board[box[0]-1][box[1]] == Obj.WALL or\n",
    "                self.board[box[0]-1][box[1]] == Obj.WALL and \n",
    "                self.board[box[0]][box[1]-1] == Obj.WALL or\n",
    "                self.board[box[0]][box[1]-1] == Obj.WALL and \n",
    "                self.board[box[0]+1][box[1]] == Obj.WALL)):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def getNextState(self, action):\n",
    "        self.num_step += 1\n",
    "        if self.isDeadlock() or self.isFinished() or self.num_step == self.max_step:\n",
    "            self.num_step = 0\n",
    "            self.updateState(self.init_state)\n",
    "            \n",
    "        reward = Reward.STEP\n",
    "        ahead = np.sum([self.state[1], self.move[action]], axis=0)\n",
    "        next_state = self.state\n",
    "        \n",
    "        if self.board[ahead[0]][ahead[1]] <= Obj.STORAGE:\n",
    "            # Ahead is empty or storage. Move the player.\n",
    "            next_state = (self.state[0], tuple(ahead))\n",
    "        elif self.board[ahead[0]][ahead[1]] >= Obj.BOX:\n",
    "            # Box or Box on storage. Check whether pushable.\n",
    "            double_ahead = np.sum([ahead, self.move[action]], axis=0)\n",
    "            \n",
    "            if self.board[double_ahead[0]][double_ahead[1]] <= Obj.STORAGE:\n",
    "                # Double ahead is empty or empty storage. Push the box.\n",
    "\n",
    "                # Add reward for the box.\n",
    "                if self.board[ahead[0]][ahead[1]] == Obj.BOX_ON_STORAGE:\n",
    "                    reward += Reward.BOX_OFF_STORAGE\n",
    "                if self.board[double_ahead[0]][double_ahead[1]] == Obj.STORAGE:\n",
    "                    reward += Reward.BOX_ON_STORAGE\n",
    "                    if len(self.state[0] - self.storages) == 1:\n",
    "                        reward += Reward.ALL_ON_STORAGE\n",
    "                        \n",
    "                elif (self.board[double_ahead[0]+1][double_ahead[1]] == Obj.WALL and \n",
    "                    self.board[double_ahead[0]][double_ahead[1]+1] == Obj.WALL or\n",
    "                    self.board[double_ahead[0]][double_ahead[1]+1] == Obj.WALL and \n",
    "                    self.board[double_ahead[0]-1][double_ahead[1]] == Obj.WALL or\n",
    "                    self.board[double_ahead[0]-1][double_ahead[1]] == Obj.WALL and \n",
    "                    self.board[double_ahead[0]][double_ahead[1]-1] == Obj.WALL or\n",
    "                    self.board[double_ahead[0]][double_ahead[1]-1] == Obj.WALL and \n",
    "                    self.board[double_ahead[0]+1][double_ahead[1]] == Obj.WALL):\n",
    "                    reward += Reward.DEADLOCK\n",
    "                \n",
    "                # Move the player.\n",
    "                next_player = tuple(ahead)\n",
    "                # Update box list\n",
    "                boxes = list(self.state[0])\n",
    "                boxes.remove(tuple(ahead))\n",
    "                boxes.append(tuple(double_ahead))\n",
    "                next_boxes = frozenset(boxes)\n",
    "                \n",
    "                next_state = (next_boxes, next_player)\n",
    "            else:\n",
    "                # Can't move because of the wall\n",
    "                reward += Reward.MOVE_TO_WALL\n",
    "        else:\n",
    "            # Can't move because of the wall\n",
    "            reward += Reward.MOVE_TO_WALL\n",
    "        \n",
    "        return next_state, reward\n",
    "    \n",
    "    def updateState(self, next_state):\n",
    "        boxes, player = self.state\n",
    "        for box in boxes:\n",
    "            self.board[box[0]][box[1]] -= Obj.BOX\n",
    "        self.board[player[0]][player[1]] -= Obj.PLAYER\n",
    "        \n",
    "        self.state = next_state\n",
    "        boxes, player = self.state\n",
    "        for box in boxes:\n",
    "            self.board[box[0]][box[1]] += Obj.BOX\n",
    "        self.board[player[0]][player[1]] += Obj.PLAYER\n",
    "\n",
    "    def getAction(self, eps):\n",
    "        if np.random.random_sample() < eps:\n",
    "            # Random move\n",
    "            action = np.random.randint(0, 4)\n",
    "        else:\n",
    "            # Pick the best action\n",
    "            action = np.argmax(self.Q[self.state])\n",
    "        return action\n",
    "    \n",
    "    def isFinished(self):\n",
    "        if self.state[0] == self.storages:\n",
    "            self.eps *= self.eps_decay_rate\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def visualize(self):\n",
    "        symbols = {\n",
    "            0: ' ',\n",
    "            1: '.',\n",
    "            2: '#',\n",
    "            3: '@',\n",
    "            4: '@',\n",
    "            5: '$',\n",
    "            6: '$'\n",
    "        }\n",
    "        for r in self.board:\n",
    "            print(''.join(map(lambda x:symbols[x], r)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab2f1438-5a5b-4c50-b73f-247918f01345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(input_file, alpha=1.0, gamma=1.0, max_iter=100000, eps=0.9, eps_decay_rate=0.9,printOpt=True):\n",
    "    \n",
    "    board_size, walls, boxes, storages, player = read_file(input_file)\n",
    "    max_step = board_size[0]*board_size[1]*len(boxes)\n",
    "    \n",
    "    solver = QLearning(board_size, walls, boxes, storages, player, max_step, eps, eps_decay_rate)\n",
    "\n",
    "    last_episode = \"\"\n",
    "    num_stalls = 0\n",
    "    num_iters_to_converge = -1\n",
    "    \n",
    "    #from tqdm import tqdm\n",
    "    for i in range(max_iter):#tqdm(range(max_iter)):\n",
    "        # Periodic evaluation for early stopping\n",
    "        if i % 100 == 0:\n",
    "            nsteps, episode = inference(solver)\n",
    "            if nsteps >= 0 and last_episode == episode:\n",
    "                num_stalls += 1\n",
    "            if num_stalls >= 5:\n",
    "                # Conclude the policy has converged if it stalls for 100 times\n",
    "                num_iters_to_converge = i\n",
    "                break\n",
    "            last_episode = episode\n",
    "        # Training\n",
    "        action = solver.getAction(solver.eps)\n",
    "        next_state, reward = solver.getNextState(action)\n",
    "        solver.Q[solver.state][action] = solver.Q[solver.state][action] + alpha*(reward + gamma*np.amax(solver.Q[next_state]) - solver.Q[solver.state][action])\n",
    "        solver.updateState(next_state)\n",
    "\n",
    "    length, episode = inference(solver, printOpt)\n",
    "    print(f\"# iters to converge: {num_iters_to_converge}\")\n",
    "    print(f\"# explored states: {len(solver.Q)}\")\n",
    "    print(f\"{length} {episode}\")\n",
    "    \n",
    "    return num_iters_to_converge, len(solver.Q), length, episode\n",
    "    \n",
    "def inference(solver, visualize=False):\n",
    "    eps = 0.0 # Greedy policy\n",
    "    orig_state = solver.state\n",
    "    solver.updateState(solver.init_state)\n",
    "    moves = []\n",
    "    len_moves, episode = -1, \"Failed finding goal\"\n",
    "    for i in range(solver.max_step):\n",
    "        action = solver.getAction(eps)\n",
    "        moves.append(solver.direction[action])\n",
    "        next_state, reward = solver.getNextState(action)\n",
    "        if visualize:\n",
    "            print(f\"best action: {solver.direction[action]}\")\n",
    "            print(solver.Q[solver.state])\n",
    "            solver.updateState(next_state)\n",
    "            solver.visualize()\n",
    "        else:\n",
    "            solver.updateState(next_state)\n",
    "        if solver.isFinished():\n",
    "            len_moves = len(moves)\n",
    "            episode = ''.join(moves)\n",
    "            break\n",
    "    \n",
    "    solver.updateState(orig_state)\n",
    "    return len_moves, episode\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "41134b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def parameter_tuning(file_name='sokoban01.txt', tuning_step=3):\n",
    "    board_size, walls, boxes, storages, player = read_file(file_name)\n",
    "    max_step = board_size[0]*board_size[1]*len(boxes)\n",
    "    opt_a=[]\n",
    "    opt_g=[]\n",
    "    opt_eps_d=[]\n",
    "    total_performance=[]\n",
    "    for i in range(0,tuning_step):\n",
    "        performance = {}\n",
    "        for alpha in np.arange(0.2, 1.1, 0.2):\n",
    "            for gamma in np.arange(0.2,1.1,0.2):\n",
    "                for eps_decay_rate in np.arange(0.5,1,0.1):\n",
    "                    alpha = round(alpha,2) ;gamma = round(gamma,2) ; eps_decay_rate = round(eps_decay_rate,2)\n",
    "                    print(alpha,gamma,eps_decay_rate)\n",
    "                    num_step, len_q , len_move, _ = solve(file_name,alpha=alpha, gamma=gamma, eps_decay_rate=eps_decay_rate,printOpt=False)\n",
    "                    performance[alpha,gamma,eps_decay_rate] = [num_step, len_q, len_move]\n",
    "        total_performance.append(performance)\n",
    "        opt_alpha, opt_gamma, opt_eps_decay_rate = [k for k, v in sorted(performance.items(), key=lambda item: (item[1][2],item[1][0],item[1][1])) if v[-1] != -1][0]\n",
    "        opt_a.append(opt_alpha)\n",
    "        opt_g.append(opt_gamma)\n",
    "        opt_eps_d.append(opt_eps_decay_rate)\n",
    "    return total_performance, opt_a, opt_g, opt_eps_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "7b7028a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_param_tuning(file_path,performance,fixed_col,fixed_value):\n",
    "    col_name={'alpha':0,'gamma':1,'decaying':2}\n",
    "    col_id = {v:k for k,v in col_name.items() }\n",
    "    fixed_col_num= col_name[fixed_col]\n",
    "    check_col_x,check_col_y= [i for i in col_name.values() if i != fixed_col_num]\n",
    "    board_size, walls, boxes, storages, player = read_file(file_path)\n",
    "    max_step = board_size[0]*board_size[1]*len(boxes)\n",
    "    revised_perf = {k: v if v[0]!= -1 else [100000,v[1], max_step] for k, v in performance.items()}\n",
    "    \n",
    "    #normalize values\n",
    "    max_step = max([v[0] for v in revised_perf.values()]) ; min_step = min([v[0] for v in revised_perf.values()])\n",
    "    max_length = max([v[-1] for v in revised_perf.values()]); min_length = min([v[-1] for v in revised_perf.values()])\n",
    "    step = {k:(v[0]-min_step) /(max_step-min_step) for k,v in revised_perf.items() if k[fixed_col_num]==fixed_value}\n",
    "    length = {k: (v[-1]-min_length) /(max_lenth-min_length) for k,v in revised_perf.items() if k[fixed_col_num]==fixed_value}\n",
    "    \n",
    "    g_e_relations ={}\n",
    "    for k in step.keys():\n",
    "        if k in g_e_relations:\n",
    "            g_e_relations[(k[check_col_x],k[check_col_y])] += 0.2 * step[k] + 0.8* length[k] # s 값도 나중에 사용 할 수 있을듯 \n",
    "        else:\n",
    "            g_e_relations[(k[check_col_x],k[check_col_y])] = 0.2* step[k] + 0.8* length[k]\n",
    "    x_range = [round(i*0.1,2) for i in np.arange(2,11,2)] # Or something else\n",
    "    if fixed_col_num !=2 :\n",
    "        y_range = [round(i*0.1,2) for i in np.arange(5,10,1)] # Or something else\n",
    "    else:\n",
    "        y_range = [round(i*0.1,2) for i in np.arange(2,11,2)]\n",
    "        \n",
    "    tr_auc = np.zeros((len(x_range),len(y_range)))\n",
    "    for i,k in enumerate(x_range):\n",
    "        for j,a in enumerate(y_range):\n",
    "            if g_e_relations[round(k,2),round(a,2)] == 1 :\n",
    "                tr_auc[i][j] = None\n",
    "            else:\n",
    "                tr_auc[i][j] = g_e_relations[round(k,2),round(a,2)]\n",
    "                \n",
    "    import matplotlib.pyplot as plt\n",
    "    f, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    cax = ax.matshow(tr_auc, interpolation='nearest')\n",
    "    f.colorbar(cax)\n",
    "    ax.set_xlabel(f'{col_id[check_col_x]} values')\n",
    "    ax.set_ylabel(f'{col_id[check_col_y]} values')\n",
    "    ax.set_xticklabels(['']+list(x_range))\n",
    "    ax.set_yticklabels(['']+list(y_range))\n",
    "    plt.title(f\"Performance of each {col_id[check_col_x]} and {col_id[check_col_y]} values\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "e036724a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.2 0.5\n",
      "# iters to converge: -1\n",
      "# explored states: 2503\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.6\n",
      "# iters to converge: 87900\n",
      "# explored states: 1560\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.2 0.7\n",
      "# iters to converge: 91200\n",
      "# explored states: 1952\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.2 0.2 0.8\n",
      "# iters to converge: 98300\n",
      "# explored states: 1882\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.2 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2578\n",
      "-1 Failed finding goal\n",
      "0.2 0.4 0.5\n",
      "# iters to converge: 59600\n",
      "# explored states: 1522\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.2 0.4 0.6\n",
      "# iters to converge: 98500\n",
      "# explored states: 2370\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.2 0.4 0.7\n",
      "# iters to converge: 83500\n",
      "# explored states: 2274\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.2 0.4 0.8\n",
      "# iters to converge: 87300\n",
      "# explored states: 2453\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.2 0.4 0.9\n",
      "# iters to converge: 92000\n",
      "# explored states: 2484\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.2 0.6 0.5\n",
      "# iters to converge: -1\n",
      "# explored states: 1158\n",
      "-1 Failed finding goal\n",
      "0.2 0.6 0.6\n",
      "# iters to converge: 66700\n",
      "# explored states: 2008\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.6 0.7\n",
      "# iters to converge: 73100\n",
      "# explored states: 2231\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.6 0.8\n",
      "# iters to converge: 68000\n",
      "# explored states: 2134\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.2 0.6 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2728\n",
      "-1 Failed finding goal\n",
      "0.2 0.8 0.5\n",
      "# iters to converge: 92000\n",
      "# explored states: 2360\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 0.8 0.6\n",
      "# iters to converge: 76500\n",
      "# explored states: 2133\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.2 0.8 0.7\n",
      "# iters to converge: 53600\n",
      "# explored states: 1790\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.2 0.8 0.8\n",
      "# iters to converge: 94200\n",
      "# explored states: 2568\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.2 0.8 0.9\n",
      "# iters to converge: 88800\n",
      "# explored states: 2498\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 1.0 0.5\n",
      "# iters to converge: 47800\n",
      "# explored states: 2216\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.2 1.0 0.6\n",
      "# iters to converge: 95700\n",
      "# explored states: 2914\n",
      "22 ULLLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.7\n",
      "# iters to converge: 52300\n",
      "# explored states: 2373\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.8\n",
      "# iters to converge: 84700\n",
      "# explored states: 2711\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.9\n",
      "# iters to converge: 76100\n",
      "# explored states: 2717\n",
      "22 ULLLRURUULLLDLURDDDLDR\n",
      "0.4 0.2 0.5\n",
      "# iters to converge: 76100\n",
      "# explored states: 2192\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.2 0.6\n",
      "# iters to converge: 58700\n",
      "# explored states: 1847\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.4 0.2 0.7\n",
      "# iters to converge: 57700\n",
      "# explored states: 2003\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.4 0.2 0.8\n",
      "# iters to converge: 80300\n",
      "# explored states: 2384\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.2 0.9\n",
      "# iters to converge: 71400\n",
      "# explored states: 2303\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.4 0.5\n",
      "# iters to converge: 48200\n",
      "# explored states: 1823\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.4 0.4 0.6\n",
      "# iters to converge: 39200\n",
      "# explored states: 1594\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.4 0.4 0.7\n",
      "# iters to converge: 66100\n",
      "# explored states: 2085\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 0.4 0.8\n",
      "# iters to converge: 65900\n",
      "# explored states: 2008\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.4 0.4 0.9\n",
      "# iters to converge: 58500\n",
      "# explored states: 2232\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.6 0.5\n",
      "# iters to converge: 43000\n",
      "# explored states: 1701\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.6 0.6\n",
      "# iters to converge: -1\n",
      "# explored states: 159\n",
      "-1 Failed finding goal\n",
      "0.4 0.6 0.7\n",
      "# iters to converge: 52500\n",
      "# explored states: 1792\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 0.6 0.8\n",
      "# iters to converge: 54700\n",
      "# explored states: 2120\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.6 0.9\n",
      "# iters to converge: 72500\n",
      "# explored states: 2514\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.4 0.8 0.5\n",
      "# iters to converge: 31700\n",
      "# explored states: 1426\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.8 0.6\n",
      "# iters to converge: -1\n",
      "# explored states: 1911\n",
      "-1 Failed finding goal\n",
      "0.4 0.8 0.7\n",
      "# iters to converge: 38600\n",
      "# explored states: 1711\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.4 0.8 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 227\n",
      "-1 Failed finding goal\n",
      "0.4 0.8 0.9\n",
      "# iters to converge: 80700\n",
      "# explored states: 2580\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 1.0 0.5\n",
      "# iters to converge: 39800\n",
      "# explored states: 2081\n",
      "22 ULLLRURUULLLDLUDRDDLDR\n",
      "0.4 1.0 0.6\n",
      "# iters to converge: 37700\n",
      "# explored states: 1970\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.7\n",
      "# iters to converge: 61800\n",
      "# explored states: 2431\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.4 1.0 0.8\n",
      "# iters to converge: 40600\n",
      "# explored states: 1895\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.9\n",
      "# iters to converge: 52800\n",
      "# explored states: 2083\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.6 0.2 0.5\n",
      "# iters to converge: 48800\n",
      "# explored states: 1824\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.2 0.6\n",
      "# iters to converge: 46400\n",
      "# explored states: 1930\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.2 0.7\n",
      "# iters to converge: 73900\n",
      "# explored states: 2269\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.6 0.2 0.8\n",
      "# iters to converge: 42000\n",
      "# explored states: 1738\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.2 0.9\n",
      "# iters to converge: 47200\n",
      "# explored states: 2112\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.6 0.4 0.5\n",
      "# iters to converge: 80100\n",
      "# explored states: 2362\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.6 0.4 0.6\n",
      "# iters to converge: 30300\n",
      "# explored states: 1299\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.4 0.7\n",
      "# iters to converge: 56100\n",
      "# explored states: 2158\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.4 0.8\n",
      "# iters to converge: 38800\n",
      "# explored states: 1735\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.6 0.4 0.9\n",
      "# iters to converge: 37900\n",
      "# explored states: 1751\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.6 0.6 0.5\n",
      "# iters to converge: 57700\n",
      "# explored states: 2006\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.6 0.6 0.6\n",
      "# iters to converge: 37300\n",
      "# explored states: 1726\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.6 0.7\n",
      "# iters to converge: 38800\n",
      "# explored states: 1691\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.6 0.6 0.8\n",
      "# iters to converge: 56900\n",
      "# explored states: 1988\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.6 0.9\n",
      "# iters to converge: 70500\n",
      "# explored states: 2328\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.6 0.8 0.5\n",
      "# iters to converge: 33000\n",
      "# explored states: 1471\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.8 0.6\n",
      "# iters to converge: 33200\n",
      "# explored states: 1574\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.6 0.8 0.7\n",
      "# iters to converge: 36400\n",
      "# explored states: 1617\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.8 0.8\n",
      "# iters to converge: 43800\n",
      "# explored states: 1932\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.8 0.9\n",
      "# iters to converge: 97400\n",
      "# explored states: 2467\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.6 1.0 0.5\n",
      "# iters to converge: 54600\n",
      "# explored states: 1959\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.6\n",
      "# iters to converge: 49500\n",
      "# explored states: 1860\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.7\n",
      "# iters to converge: 37800\n",
      "# explored states: 2177\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.8\n",
      "# iters to converge: 69600\n",
      "# explored states: 2190\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.6 1.0 0.9\n",
      "# iters to converge: 50400\n",
      "# explored states: 2162\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.8 0.2 0.5\n",
      "# iters to converge: 40400\n",
      "# explored states: 1856\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.8 0.2 0.6\n",
      "# iters to converge: 77400\n",
      "# explored states: 2308\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.2 0.7\n",
      "# iters to converge: 44700\n",
      "# explored states: 1786\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.8 0.2 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 2957\n",
      "-1 Failed finding goal\n",
      "0.8 0.2 0.9\n",
      "# iters to converge: 94600\n",
      "# explored states: 2500\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.4 0.5\n",
      "# iters to converge: 83700\n",
      "# explored states: 2495\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.8 0.4 0.6\n",
      "# iters to converge: 74400\n",
      "# explored states: 2328\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.8 0.4 0.7\n",
      "# iters to converge: 44700\n",
      "# explored states: 1934\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.4 0.8\n",
      "# iters to converge: 56800\n",
      "# explored states: 2097\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.4 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# iters to converge: 44000\n",
      "# explored states: 2117\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.8 0.6 0.5\n",
      "# iters to converge: 26800\n",
      "# explored states: 1475\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.8 0.6 0.6\n",
      "# iters to converge: 26500\n",
      "# explored states: 1391\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.6 0.7\n",
      "# iters to converge: 48000\n",
      "# explored states: 1939\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.8 0.6 0.8\n",
      "# iters to converge: 34700\n",
      "# explored states: 1847\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.8 0.6 0.9\n",
      "# iters to converge: 44900\n",
      "# explored states: 1948\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.8 0.8 0.5\n",
      "# iters to converge: 33400\n",
      "# explored states: 1650\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.8 0.8 0.6\n",
      "# iters to converge: 35500\n",
      "# explored states: 1767\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.8 0.8 0.7\n",
      "# iters to converge: -1\n",
      "# explored states: 154\n",
      "-1 Failed finding goal\n",
      "0.8 0.8 0.8\n",
      "# iters to converge: 41200\n",
      "# explored states: 1945\n",
      "40 ULLURUULLLDLURRRRDDLDLDLURRURUULLLDDDLDR\n",
      "0.8 0.8 0.9\n",
      "# iters to converge: 44600\n",
      "# explored states: 2093\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 1.0 0.5\n",
      "# iters to converge: 35500\n",
      "# explored states: 1627\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.8 1.0 0.6\n",
      "# iters to converge: 23100\n",
      "# explored states: 1879\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.7\n",
      "# iters to converge: 18300\n",
      "# explored states: 1420\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.8 1.0 0.8\n",
      "# iters to converge: 38800\n",
      "# explored states: 1881\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.8 1.0 0.9\n",
      "# iters to converge: 23600\n",
      "# explored states: 1587\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 0.2 0.5\n",
      "# iters to converge: 63700\n",
      "# explored states: 2431\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.2 0.6\n",
      "# iters to converge: 37300\n",
      "# explored states: 1776\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 0.2 0.7\n",
      "# iters to converge: 19400\n",
      "# explored states: 1246\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.2 0.8\n",
      "# iters to converge: 25400\n",
      "# explored states: 1475\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.2 0.9\n",
      "# iters to converge: 49900\n",
      "# explored states: 2158\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.5\n",
      "# iters to converge: 24400\n",
      "# explored states: 1499\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.6\n",
      "# iters to converge: 37200\n",
      "# explored states: 1780\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.4 0.7\n",
      "# iters to converge: 27100\n",
      "# explored states: 1679\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.8\n",
      "# iters to converge: 35400\n",
      "# explored states: 1757\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.9\n",
      "# iters to converge: 65500\n",
      "# explored states: 2493\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 0.6 0.5\n",
      "# iters to converge: 26400\n",
      "# explored states: 1641\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.6 0.6\n",
      "# iters to converge: 38800\n",
      "# explored states: 1994\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.6 0.7\n",
      "# iters to converge: 61300\n",
      "# explored states: 2220\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.6 0.8\n",
      "# iters to converge: 36100\n",
      "# explored states: 1740\n",
      "40 ULLURUULLLDLURRRRDDLDLDLURRURUULLLDDDLDR\n",
      "1.0 0.6 0.9\n",
      "# iters to converge: 42100\n",
      "# explored states: 2004\n",
      "42 ULLURUULLLDLURRRRDDLDLDLURRRUUUULDLLDDDLDR\n",
      "1.0 0.8 0.5\n",
      "# iters to converge: 40100\n",
      "# explored states: 1727\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.8 0.6\n",
      "# iters to converge: 19900\n",
      "# explored states: 1303\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.8 0.7\n",
      "# iters to converge: 23400\n",
      "# explored states: 1672\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.8 0.8\n",
      "# iters to converge: 38500\n",
      "# explored states: 1848\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.8 0.9\n",
      "# iters to converge: 46800\n",
      "# explored states: 1830\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 1.0 0.5\n",
      "# iters to converge: 22900\n",
      "# explored states: 1647\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.6\n",
      "# iters to converge: 27500\n",
      "# explored states: 1759\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.7\n",
      "# iters to converge: 18500\n",
      "# explored states: 1460\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.8\n",
      "# iters to converge: 30700\n",
      "# explored states: 1626\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.9\n",
      "# iters to converge: 34800\n",
      "# explored states: 1633\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.2 0.2 0.5\n",
      "# iters to converge: 93200\n",
      "# explored states: 1800\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.2 0.2 0.6\n",
      "# iters to converge: -1\n",
      "# explored states: 2459\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.7\n",
      "# iters to converge: 92300\n",
      "# explored states: 1922\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 0.2 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 2491\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2771\n",
      "-1 Failed finding goal\n",
      "0.2 0.4 0.5\n",
      "# iters to converge: -1\n",
      "# explored states: 2516\n",
      "-1 Failed finding goal\n",
      "0.2 0.4 0.6\n",
      "# iters to converge: 79700\n",
      "# explored states: 1960\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 0.4 0.7\n",
      "# iters to converge: 79500\n",
      "# explored states: 1943\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.2 0.4 0.8\n",
      "# iters to converge: 86000\n",
      "# explored states: 2428\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.2 0.4 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2640\n",
      "-1 Failed finding goal\n",
      "0.2 0.6 0.5\n",
      "# iters to converge: 87500\n",
      "# explored states: 2356\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.2 0.6 0.6\n",
      "# iters to converge: 87200\n",
      "# explored states: 2175\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.2 0.6 0.7\n",
      "# iters to converge: 57400\n",
      "# explored states: 1805\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 0.6 0.8\n",
      "# iters to converge: 81400\n",
      "# explored states: 2295\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.2 0.6 0.9\n",
      "# iters to converge: 69400\n",
      "# explored states: 2264\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.8 0.5\n",
      "# iters to converge: 92500\n",
      "# explored states: 2510\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.2 0.8 0.6\n",
      "# iters to converge: 73600\n",
      "# explored states: 2076\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.8 0.7\n",
      "# iters to converge: 67200\n",
      "# explored states: 2137\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.2 0.8 0.8\n",
      "# iters to converge: 70300\n",
      "# explored states: 2065\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 0.8 0.9\n",
      "# iters to converge: 83400\n",
      "# explored states: 2219\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.2 1.0 0.5\n",
      "# iters to converge: 59100\n",
      "# explored states: 2202\n",
      "22 ULLLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.6\n",
      "# iters to converge: 93700\n",
      "# explored states: 2900\n",
      "22 ULLLRURUULLLDLUDRDDLDR\n",
      "0.2 1.0 0.7\n",
      "# iters to converge: 51200\n",
      "# explored states: 2305\n",
      "22 ULLLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.8\n",
      "# iters to converge: 61300\n",
      "# explored states: 2445\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.9\n",
      "# iters to converge: 50800\n",
      "# explored states: 2268\n",
      "23 ULULLRURUULLLDLURDDDLDR\n",
      "0.4 0.2 0.5\n",
      "# iters to converge: 59200\n",
      "# explored states: 2048\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.2 0.6\n",
      "# iters to converge: 96300\n",
      "# explored states: 2592\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.2 0.7\n",
      "# iters to converge: 50900\n",
      "# explored states: 1597\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.2 0.8\n",
      "# iters to converge: 61200\n",
      "# explored states: 2101\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.2 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2578\n",
      "-1 Failed finding goal\n",
      "0.4 0.4 0.5\n",
      "# iters to converge: 62600\n",
      "# explored states: 2071\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.4 0.6\n",
      "# iters to converge: 44400\n",
      "# explored states: 1439\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.4 0.7\n",
      "# iters to converge: 78100\n",
      "# explored states: 2241\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.4 0.8\n",
      "# iters to converge: 50100\n",
      "# explored states: 1991\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.4 0.9\n",
      "# iters to converge: 61500\n",
      "# explored states: 2366\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.6 0.5\n",
      "# iters to converge: 41800\n",
      "# explored states: 1637\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 0.6 0.6\n",
      "# iters to converge: 61500\n",
      "# explored states: 2000\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.4 0.6 0.7\n",
      "# iters to converge: 41300\n",
      "# explored states: 1630\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.4 0.6 0.8\n",
      "# iters to converge: 55500\n",
      "# explored states: 1995\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.4 0.6 0.9\n",
      "# iters to converge: 78100\n",
      "# explored states: 2451\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.8 0.5\n",
      "# iters to converge: 32200\n",
      "# explored states: 1470\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.8 0.6\n",
      "# iters to converge: 74300\n",
      "# explored states: 2306\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.4 0.8 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# iters to converge: 31700\n",
      "# explored states: 1414\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.4 0.8 0.8\n",
      "# iters to converge: 43300\n",
      "# explored states: 1917\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.4 0.8 0.9\n",
      "# iters to converge: 45400\n",
      "# explored states: 1847\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 1.0 0.5\n",
      "# iters to converge: 23000\n",
      "# explored states: 1518\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.4 1.0 0.6\n",
      "# iters to converge: 57200\n",
      "# explored states: 2481\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.7\n",
      "# iters to converge: 58500\n",
      "# explored states: 2340\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.8\n",
      "# iters to converge: 51300\n",
      "# explored states: 2293\n",
      "22 ULLLRURUULLLDLUDRDDLDR\n",
      "0.4 1.0 0.9\n",
      "# iters to converge: 30200\n",
      "# explored states: 1788\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 0.2 0.5\n",
      "# iters to converge: 44200\n",
      "# explored states: 1846\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.2 0.6\n",
      "# iters to converge: 54800\n",
      "# explored states: 2114\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.6 0.2 0.7\n",
      "# iters to converge: 35300\n",
      "# explored states: 1648\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.2 0.8\n",
      "# iters to converge: 50900\n",
      "# explored states: 1947\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.2 0.9\n",
      "# iters to converge: 56000\n",
      "# explored states: 2354\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.6 0.4 0.5\n",
      "# iters to converge: 90600\n",
      "# explored states: 2570\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.4 0.6\n",
      "# iters to converge: 51600\n",
      "# explored states: 2147\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.4 0.7\n",
      "# iters to converge: 31300\n",
      "# explored states: 1473\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.4 0.8\n",
      "# iters to converge: 30300\n",
      "# explored states: 1627\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.6 0.4 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 134\n",
      "-1 Failed finding goal\n",
      "0.6 0.6 0.5\n",
      "# iters to converge: 34800\n",
      "# explored states: 1745\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.6 0.6\n",
      "# iters to converge: 21100\n",
      "# explored states: 1052\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.6 0.6 0.7\n",
      "# iters to converge: 30600\n",
      "# explored states: 1561\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.6 0.6 0.8\n",
      "# iters to converge: 43500\n",
      "# explored states: 1973\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.6 0.6 0.9\n",
      "# iters to converge: 73100\n",
      "# explored states: 2388\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.8 0.5\n",
      "# iters to converge: 57400\n",
      "# explored states: 1908\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.8 0.6\n",
      "# iters to converge: -1\n",
      "# explored states: 167\n",
      "-1 Failed finding goal\n",
      "0.6 0.8 0.7\n",
      "# iters to converge: 66400\n",
      "# explored states: 2314\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.8 0.8\n",
      "# iters to converge: 41600\n",
      "# explored states: 1772\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.8 0.9\n",
      "# iters to converge: 56200\n",
      "# explored states: 2140\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 1.0 0.5\n",
      "# iters to converge: 23200\n",
      "# explored states: 1523\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.6\n",
      "# iters to converge: 37700\n",
      "# explored states: 2206\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.6 1.0 0.7\n",
      "# iters to converge: -1\n",
      "# explored states: 1133\n",
      "-1 Failed finding goal\n",
      "0.6 1.0 0.8\n",
      "# iters to converge: 23200\n",
      "# explored states: 1600\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.6 1.0 0.9\n",
      "# iters to converge: 26700\n",
      "# explored states: 1784\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 0.2 0.5\n",
      "# iters to converge: 59500\n",
      "# explored states: 2258\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.8 0.2 0.6\n",
      "# iters to converge: 67200\n",
      "# explored states: 2476\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.8 0.2 0.7\n",
      "# iters to converge: 56300\n",
      "# explored states: 2314\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.2 0.8\n",
      "# iters to converge: 42400\n",
      "# explored states: 1973\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.2 0.9\n",
      "# iters to converge: 74600\n",
      "# explored states: 2689\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.8 0.4 0.5\n",
      "# iters to converge: 51800\n",
      "# explored states: 2020\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.8 0.4 0.6\n",
      "# iters to converge: 61100\n",
      "# explored states: 2287\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.4 0.7\n",
      "# iters to converge: 38100\n",
      "# explored states: 1917\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.8 0.4 0.8\n",
      "# iters to converge: 46000\n",
      "# explored states: 2018\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.4 0.9\n",
      "# iters to converge: 39400\n",
      "# explored states: 1807\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.8 0.6 0.5\n",
      "# iters to converge: 67000\n",
      "# explored states: 2182\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.6 0.6\n",
      "# iters to converge: 36900\n",
      "# explored states: 1937\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.8 0.6 0.7\n",
      "# iters to converge: 47900\n",
      "# explored states: 2068\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.8 0.6 0.8\n",
      "# iters to converge: 29700\n",
      "# explored states: 1740\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.6 0.9\n",
      "# iters to converge: 66800\n",
      "# explored states: 2410\n",
      "38 ULLURUULLLDLURRRRDDDLLRRUUUULDLLDDDLDR\n",
      "0.8 0.8 0.5\n",
      "# iters to converge: 38000\n",
      "# explored states: 1724\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.8 0.6\n",
      "# iters to converge: 44100\n",
      "# explored states: 1791\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.8 0.8 0.7\n",
      "# iters to converge: 32300\n",
      "# explored states: 1652\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.8 0.8\n",
      "# iters to converge: 83900\n",
      "# explored states: 2393\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.8 0.9\n",
      "# iters to converge: 60500\n",
      "# explored states: 2133\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 1.0 0.5\n",
      "# iters to converge: 37100\n",
      "# explored states: 2090\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.6\n",
      "# iters to converge: 28400\n",
      "# explored states: 1605\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.7\n",
      "# iters to converge: 31800\n",
      "# explored states: 1959\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.8\n",
      "# iters to converge: 26800\n",
      "# explored states: 1572\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.8 1.0 0.9\n",
      "# iters to converge: 45600\n",
      "# explored states: 1979\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "1.0 0.2 0.5\n",
      "# iters to converge: 60500\n",
      "# explored states: 2335\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 0.2 0.6\n",
      "# iters to converge: 24600\n",
      "# explored states: 1454\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.2 0.7\n",
      "# iters to converge: 25500\n",
      "# explored states: 1574\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.2 0.8\n",
      "# iters to converge: 32800\n",
      "# explored states: 1662\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.2 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 1407\n",
      "-1 Failed finding goal\n",
      "1.0 0.4 0.5\n",
      "# iters to converge: 38700\n",
      "# explored states: 1828\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.4 0.6\n",
      "# iters to converge: 73700\n",
      "# explored states: 2526\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "1.0 0.4 0.7\n",
      "# iters to converge: 43900\n",
      "# explored states: 1988\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 0.4 0.8\n",
      "# iters to converge: 29100\n",
      "# explored states: 1713\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.4 0.9\n",
      "# iters to converge: 31600\n",
      "# explored states: 1722\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 0.6 0.5\n",
      "# iters to converge: 37300\n",
      "# explored states: 1763\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 0.6 0.6\n",
      "# iters to converge: 84500\n",
      "# explored states: 2476\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.6 0.7\n",
      "# iters to converge: 38200\n",
      "# explored states: 1749\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.6 0.8\n",
      "# iters to converge: 31200\n",
      "# explored states: 1710\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.6 0.9\n",
      "# iters to converge: 37100\n",
      "# explored states: 1796\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "1.0 0.8 0.5\n",
      "# iters to converge: 43600\n",
      "# explored states: 1865\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "1.0 0.8 0.6\n",
      "# iters to converge: 46800\n",
      "# explored states: 1859\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "1.0 0.8 0.7\n",
      "# iters to converge: 56400\n",
      "# explored states: 2070\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.8 0.8\n",
      "# iters to converge: 58300\n",
      "# explored states: 2039\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.8 0.9\n",
      "# iters to converge: 36200\n",
      "# explored states: 1808\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 1.0 0.5\n",
      "# iters to converge: 45900\n",
      "# explored states: 2119\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.6\n",
      "# iters to converge: 18200\n",
      "# explored states: 1451\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.7\n",
      "# iters to converge: 20500\n",
      "# explored states: 1707\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.8\n",
      "# iters to converge: 33000\n",
      "# explored states: 2340\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.9\n",
      "# iters to converge: 58900\n",
      "# explored states: 2166\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.2 0.2 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# iters to converge: -1\n",
      "# explored states: 2033\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.6\n",
      "# iters to converge: -1\n",
      "# explored states: 2421\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.7\n",
      "# iters to converge: 90700\n",
      "# explored states: 1701\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.2 0.2 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 2526\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2533\n",
      "-1 Failed finding goal\n",
      "0.2 0.4 0.5\n",
      "# iters to converge: 63500\n",
      "# explored states: 1571\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.2 0.4 0.6\n",
      "# iters to converge: 66700\n",
      "# explored states: 1732\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.2 0.4 0.7\n",
      "# iters to converge: -1\n",
      "# explored states: 2532\n",
      "-1 Failed finding goal\n",
      "0.2 0.4 0.8\n",
      "# iters to converge: 76100\n",
      "# explored states: 2015\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.2 0.4 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2881\n",
      "-1 Failed finding goal\n",
      "0.2 0.6 0.5\n",
      "# iters to converge: 73500\n",
      "# explored states: 2018\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.2 0.6 0.6\n",
      "# iters to converge: 56300\n",
      "# explored states: 1798\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 0.6 0.7\n",
      "# iters to converge: 68500\n",
      "# explored states: 1993\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.2 0.6 0.8\n",
      "# iters to converge: 60400\n",
      "# explored states: 1917\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.6 0.9\n",
      "# iters to converge: 96100\n",
      "# explored states: 2544\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.2 0.8 0.5\n",
      "# iters to converge: 47700\n",
      "# explored states: 1614\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.8 0.6\n",
      "# iters to converge: 52600\n",
      "# explored states: 1797\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.8 0.7\n",
      "# iters to converge: 86700\n",
      "# explored states: 2097\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.2 0.8 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 123\n",
      "-1 Failed finding goal\n",
      "0.2 0.8 0.9\n",
      "# iters to converge: 73100\n",
      "# explored states: 2387\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.2 1.0 0.5\n",
      "# iters to converge: 57800\n",
      "# explored states: 2323\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.6\n",
      "# iters to converge: 47900\n",
      "# explored states: 2219\n",
      "22 ULLLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.7\n",
      "# iters to converge: 52400\n",
      "# explored states: 2194\n",
      "22 ULLLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.8\n",
      "# iters to converge: 73500\n",
      "# explored states: 2706\n",
      "22 ULLLRURUULLLDLUDRDDLDR\n",
      "0.2 1.0 0.9\n",
      "# iters to converge: 51100\n",
      "# explored states: 2315\n",
      "22 ULLLRURUULLLDLUDRDDLDR\n",
      "0.4 0.2 0.5\n",
      "# iters to converge: 72200\n",
      "# explored states: 2236\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.2 0.6\n",
      "# iters to converge: 77500\n",
      "# explored states: 2291\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.2 0.7\n",
      "# iters to converge: 52200\n",
      "# explored states: 1853\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.4 0.2 0.8\n",
      "# iters to converge: 96600\n",
      "# explored states: 2486\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.4 0.2 0.9\n",
      "# iters to converge: 81100\n",
      "# explored states: 2438\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.4 0.5\n",
      "# iters to converge: 50600\n",
      "# explored states: 1987\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.4 0.6\n",
      "# iters to converge: 55300\n",
      "# explored states: 2045\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.4 0.7\n",
      "# iters to converge: 80200\n",
      "# explored states: 2361\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.4 0.4 0.8\n",
      "# iters to converge: 42200\n",
      "# explored states: 1670\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 0.4 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 1395\n",
      "-1 Failed finding goal\n",
      "0.4 0.6 0.5\n",
      "# iters to converge: 57900\n",
      "# explored states: 2024\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 0.6 0.6\n",
      "# iters to converge: 31400\n",
      "# explored states: 1404\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.6 0.7\n",
      "# iters to converge: 68600\n",
      "# explored states: 2101\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.6 0.8\n",
      "# iters to converge: 46100\n",
      "# explored states: 2061\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.4 0.6 0.9\n",
      "# iters to converge: 41700\n",
      "# explored states: 1739\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.4 0.8 0.5\n",
      "# iters to converge: 39700\n",
      "# explored states: 1922\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.8 0.6\n",
      "# iters to converge: 43600\n",
      "# explored states: 1817\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.8 0.7\n",
      "# iters to converge: 29100\n",
      "# explored states: 1444\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.8 0.8\n",
      "# iters to converge: 35400\n",
      "# explored states: 1615\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.4 0.8 0.9\n",
      "# iters to converge: 49700\n",
      "# explored states: 2034\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 1.0 0.5\n",
      "# iters to converge: 54300\n",
      "# explored states: 2245\n",
      "22 ULLLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.6\n",
      "# iters to converge: 59600\n",
      "# explored states: 2270\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.7\n",
      "# iters to converge: 34700\n",
      "# explored states: 2050\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.4 1.0 0.8\n",
      "# iters to converge: 34000\n",
      "# explored states: 2030\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.9\n",
      "# iters to converge: 71500\n",
      "# explored states: 2473\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 0.2 0.5\n",
      "# iters to converge: 79600\n",
      "# explored states: 2440\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.2 0.6\n",
      "# iters to converge: 40300\n",
      "# explored states: 1676\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.2 0.7\n",
      "# iters to converge: 59800\n",
      "# explored states: 2264\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.2 0.8\n",
      "# iters to converge: 56900\n",
      "# explored states: 1988\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.2 0.9\n",
      "# iters to converge: 58800\n",
      "# explored states: 2249\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.4 0.5\n",
      "# iters to converge: 55900\n",
      "# explored states: 2092\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.6 0.4 0.6\n",
      "# iters to converge: 50800\n",
      "# explored states: 2004\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.4 0.7\n",
      "# iters to converge: 41900\n",
      "# explored states: 1697\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.4 0.8\n",
      "# iters to converge: 46900\n",
      "# explored states: 1993\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.6 0.4 0.9\n",
      "# iters to converge: 78600\n",
      "# explored states: 2603\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.6 0.5\n",
      "# iters to converge: 41700\n",
      "# explored states: 1769\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.6 0.6\n",
      "# iters to converge: 55000\n",
      "# explored states: 1971\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.6 0.7\n",
      "# iters to converge: 33900\n",
      "# explored states: 1669\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.6 0.6 0.8\n",
      "# iters to converge: 44300\n",
      "# explored states: 2025\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.6 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 87\n",
      "-1 Failed finding goal\n",
      "0.6 0.8 0.5\n",
      "# iters to converge: 52200\n",
      "# explored states: 2051\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.6 0.8 0.6\n",
      "# iters to converge: 27200\n",
      "# explored states: 1467\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.8 0.7\n",
      "# iters to converge: 58300\n",
      "# explored states: 2125\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.6 0.8 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 252\n",
      "-1 Failed finding goal\n",
      "0.6 0.8 0.9\n",
      "# iters to converge: 41800\n",
      "# explored states: 1939\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 1.0 0.5\n",
      "# iters to converge: 40800\n",
      "# explored states: 2039\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.6\n",
      "# iters to converge: 29300\n",
      "# explored states: 1916\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.7\n",
      "# iters to converge: 21400\n",
      "# explored states: 1658\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.8\n",
      "# iters to converge: 35500\n",
      "# explored states: 1975\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.6 1.0 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 1785\n",
      "-1 Failed finding goal\n",
      "0.8 0.2 0.5\n",
      "# iters to converge: 22000\n",
      "# explored states: 1298\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.2 0.6\n",
      "# iters to converge: 33600\n",
      "# explored states: 1806\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.8 0.2 0.7\n",
      "# iters to converge: 25000\n",
      "# explored states: 1439\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.8 0.2 0.8\n",
      "# iters to converge: 45900\n",
      "# explored states: 1947\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.2 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 713\n",
      "-1 Failed finding goal\n",
      "0.8 0.4 0.5\n",
      "# iters to converge: 46700\n",
      "# explored states: 2000\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.4 0.6\n",
      "# iters to converge: 45900\n",
      "# explored states: 2023\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.4 0.7\n",
      "# iters to converge: 32100\n",
      "# explored states: 1742\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.8 0.4 0.8\n",
      "# iters to converge: 32100\n",
      "# explored states: 1693\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.4 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# iters to converge: 47900\n",
      "# explored states: 2029\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.8 0.6 0.5\n",
      "# iters to converge: 29100\n",
      "# explored states: 1599\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.8 0.6 0.6\n",
      "# iters to converge: 34300\n",
      "# explored states: 1791\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.6 0.7\n",
      "# iters to converge: 27800\n",
      "# explored states: 1570\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.8 0.6 0.8\n",
      "# iters to converge: 34800\n",
      "# explored states: 1732\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.6 0.9\n",
      "# iters to converge: 32200\n",
      "# explored states: 1646\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.8 0.5\n",
      "# iters to converge: 76700\n",
      "# explored states: 2469\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.8 0.6\n",
      "# iters to converge: 31900\n",
      "# explored states: 1708\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.8 0.8 0.7\n",
      "# iters to converge: 26300\n",
      "# explored states: 1303\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.8 0.8 0.8\n",
      "# iters to converge: 84400\n",
      "# explored states: 2461\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.8 0.8 0.9\n",
      "# iters to converge: 44300\n",
      "# explored states: 1829\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.8 1.0 0.5\n",
      "# iters to converge: 32600\n",
      "# explored states: 1792\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.6\n",
      "# iters to converge: 25000\n",
      "# explored states: 1474\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.7\n",
      "# iters to converge: 37700\n",
      "# explored states: 2042\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.8\n",
      "# iters to converge: 29800\n",
      "# explored states: 1596\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.9\n",
      "# iters to converge: 43800\n",
      "# explored states: 1889\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "1.0 0.2 0.5\n",
      "# iters to converge: 22300\n",
      "# explored states: 1440\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.2 0.6\n",
      "# iters to converge: 26300\n",
      "# explored states: 1726\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.2 0.7\n",
      "# iters to converge: 41700\n",
      "# explored states: 1997\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "1.0 0.2 0.8\n",
      "# iters to converge: 42100\n",
      "# explored states: 2083\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "1.0 0.2 0.9\n",
      "# iters to converge: 26600\n",
      "# explored states: 1650\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.5\n",
      "# iters to converge: -1\n",
      "# explored states: 209\n",
      "-1 Failed finding goal\n",
      "1.0 0.4 0.6\n",
      "# iters to converge: 22500\n",
      "# explored states: 1406\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.4 0.7\n",
      "# iters to converge: 50900\n",
      "# explored states: 1990\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.4 0.8\n",
      "# iters to converge: 29800\n",
      "# explored states: 1719\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.9\n",
      "# iters to converge: 45400\n",
      "# explored states: 2088\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.6 0.5\n",
      "# iters to converge: 36500\n",
      "# explored states: 1704\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "1.0 0.6 0.6\n",
      "# iters to converge: 24500\n",
      "# explored states: 1455\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.6 0.7\n",
      "# iters to converge: 54100\n",
      "# explored states: 2056\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.6 0.8\n",
      "# iters to converge: 24600\n",
      "# explored states: 1481\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.6 0.9\n",
      "# iters to converge: 39900\n",
      "# explored states: 1752\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "1.0 0.8 0.5\n",
      "# iters to converge: 27500\n",
      "# explored states: 1379\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.8 0.6\n",
      "# iters to converge: 70500\n",
      "# explored states: 2254\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "1.0 0.8 0.7\n",
      "# iters to converge: 25100\n",
      "# explored states: 1527\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.8 0.8\n",
      "# iters to converge: 42300\n",
      "# explored states: 1921\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.8 0.9\n",
      "# iters to converge: 35100\n",
      "# explored states: 1497\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 1.0 0.5\n",
      "# iters to converge: 19500\n",
      "# explored states: 1389\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.6\n",
      "# iters to converge: 34900\n",
      "# explored states: 2368\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.7\n",
      "# iters to converge: 24800\n",
      "# explored states: 1641\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "1.0 1.0 0.8\n",
      "# iters to converge: 21700\n",
      "# explored states: 1600\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.9\n",
      "# iters to converge: 51200\n",
      "# explored states: 2087\n",
      "22 LULLRURUULLLDLURDDDLDR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mx/yb710wvs5g99pv88g5f37t2r0000gn/T/ipykernel_1147/4222137563.py:42: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(['']+list(x_range))\n",
      "/var/folders/mx/yb710wvs5g99pv88g5f37t2r0000gn/T/ipykernel_1147/4222137563.py:43: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(['']+list(y_range))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_name = 'sokoban01.txt'\n",
    "t_performance, opt_a, opt_g, opt_eps_d = parameter_tuning(file_name=file_name)\n",
    "visualize_param_tuning('sokoban01.txt',t_performance[0],'alpha',np.median(opt_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1499bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
