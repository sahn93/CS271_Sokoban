{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c4ba328-3d89-4983-8c77-63527149aba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "#. #   #\n",
      "#  $   #\n",
      "#   # ##\n",
      "## # $.#\n",
      "#   $  #\n",
      "#  .# @#\n",
      "########\n"
     ]
    }
   ],
   "source": [
    "def read_file(path: str):\n",
    "    def parse_data(line: str) -> list[(int, int)]:\n",
    "        data = list(map(int, line.split()))\n",
    "        coordinates = []\n",
    "        for i in range(data[0]):\n",
    "            coordinates.append((data[i*2 + 1]-1, data[(i+1)*2]-1))\n",
    "        return coordinates\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        board_size = tuple(map(int, f.readline().split()))\n",
    "        walls = parse_data(f.readline())\n",
    "        boxes = parse_data(f.readline())\n",
    "        storages = parse_data(f.readline())\n",
    "        player = tuple(map(lambda x: int(x)-1, f.readline().split()))\n",
    "        \n",
    "    return board_size, walls, boxes, storages, player\n",
    "\n",
    "def visualize(data):\n",
    "    board_size, walls, boxes, storages, player = data\n",
    "    board = [[' '] * board_size[1] for _ in range(board_size[0])]\n",
    "    for r, c in walls:\n",
    "        board[r][c] = '#'\n",
    "    for r, c in boxes:\n",
    "        board[r][c] = '$'\n",
    "    for r, c in storages:\n",
    "        board[r][c] = '.'\n",
    "    board[player[0]][player[1]] = '@'\n",
    "    \n",
    "    for r in board:\n",
    "        print(''.join(r))\n",
    "    \n",
    "data = read_file('sokoban01.txt')\n",
    "visualize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "648a2d4c-917e-417a-98b9-04ec7bd314c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "class Reward:\n",
    "    STEP = -0.1\n",
    "    BOX_ON_STORAGE = 1.0\n",
    "    BOX_OFF_STORAGE = -1.0\n",
    "    ALL_ON_STORAGE = 10.0\n",
    "    DEADLOCK = -10.0\n",
    "    MOVE_TO_WALL = -1.0\n",
    "\n",
    "class Obj:\n",
    "    EMPTY = 0\n",
    "    STORAGE = 1\n",
    "    PLAYER = 2\n",
    "    PLAYER_ON_STORAGE = 3\n",
    "    WALL = 4\n",
    "    BOX = 5\n",
    "    BOX_ON_STORAGE = 6\n",
    "\n",
    "class QLearning:\n",
    "    def __init__(self, board_size, walls, boxes, storages, player, max_step, eps, eps_decay_rate):\n",
    "        self.Q = collections.defaultdict(lambda:np.zeros(4))\n",
    "        self.eps = eps\n",
    "        self.eps_decay_rate = eps_decay_rate\n",
    "        self.num_step = 0\n",
    "        self.max_step = max_step\n",
    "        self.board_size = board_size\n",
    "        self.walls = frozenset(walls)\n",
    "        self.storages = frozenset(storages)\n",
    "        self.state = (frozenset(boxes), player)\n",
    "        self.init_state = (frozenset(boxes), player)\n",
    "        self.board = [[0] * self.board_size[1] for _ in range(self.board_size[0])]\n",
    "        for box in boxes:\n",
    "            self.board[box[0]][box[1]] += Obj.BOX\n",
    "        self.board[player[0]][player[1]] += Obj.PLAYER\n",
    "        for wall in walls:\n",
    "            self.board[wall[0]][wall[1]] += Obj.WALL\n",
    "        for storage in storages:\n",
    "            self.board[storage[0]][storage[1]] += Obj.STORAGE\n",
    "        \n",
    "        self.move = {\n",
    "            0: (0, -1), # Left\n",
    "            1: (-1, 0), # Up\n",
    "            2: (0, 1),   # Right\n",
    "            3: (1, 0),  # Down\n",
    "        }\n",
    "        \n",
    "        self.direction = {\n",
    "            0: \"L\",\n",
    "            1: \"U\",\n",
    "            2: \"R\",\n",
    "            3: \"D\"\n",
    "        }\n",
    "        \n",
    "    def isDeadlock(self):\n",
    "        for box in self.state[0]:\n",
    "            if (self.board[box[0]][box[1]] != Obj.BOX_ON_STORAGE and\n",
    "                (self.board[box[0]+1][box[1]] == Obj.WALL and \n",
    "                self.board[box[0]][box[1]+1] == Obj.WALL or\n",
    "                self.board[box[0]][box[1]+1] == Obj.WALL and \n",
    "                self.board[box[0]-1][box[1]] == Obj.WALL or\n",
    "                self.board[box[0]-1][box[1]] == Obj.WALL and \n",
    "                self.board[box[0]][box[1]-1] == Obj.WALL or\n",
    "                self.board[box[0]][box[1]-1] == Obj.WALL and \n",
    "                self.board[box[0]+1][box[1]] == Obj.WALL)):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def getNextState(self, action):\n",
    "        self.num_step += 1\n",
    "        if self.isDeadlock() or self.isFinished() or self.num_step == self.max_step:\n",
    "            self.num_step = 0\n",
    "            self.updateState(self.init_state)\n",
    "            \n",
    "        reward = Reward.STEP\n",
    "        ahead = np.sum([self.state[1], self.move[action]], axis=0)\n",
    "        next_state = self.state\n",
    "        \n",
    "        if self.board[ahead[0]][ahead[1]] <= Obj.STORAGE:\n",
    "            # Ahead is empty or storage. Move the player.\n",
    "            next_state = (self.state[0], tuple(ahead))\n",
    "        elif self.board[ahead[0]][ahead[1]] >= Obj.BOX:\n",
    "            # Box or Box on storage. Check whether pushable.\n",
    "            double_ahead = np.sum([ahead, self.move[action]], axis=0)\n",
    "            \n",
    "            if self.board[double_ahead[0]][double_ahead[1]] <= Obj.STORAGE:\n",
    "                # Double ahead is empty or empty storage. Push the box.\n",
    "\n",
    "                # Add reward for the box.\n",
    "                if self.board[ahead[0]][ahead[1]] == Obj.BOX_ON_STORAGE:\n",
    "                    reward += Reward.BOX_OFF_STORAGE\n",
    "                if self.board[double_ahead[0]][double_ahead[1]] == Obj.STORAGE:\n",
    "                    reward += Reward.BOX_ON_STORAGE\n",
    "                    if len(self.state[0] - self.storages) == 1:\n",
    "                        reward += Reward.ALL_ON_STORAGE\n",
    "                        \n",
    "                elif (self.board[double_ahead[0]+1][double_ahead[1]] == Obj.WALL and \n",
    "                    self.board[double_ahead[0]][double_ahead[1]+1] == Obj.WALL or\n",
    "                    self.board[double_ahead[0]][double_ahead[1]+1] == Obj.WALL and \n",
    "                    self.board[double_ahead[0]-1][double_ahead[1]] == Obj.WALL or\n",
    "                    self.board[double_ahead[0]-1][double_ahead[1]] == Obj.WALL and \n",
    "                    self.board[double_ahead[0]][double_ahead[1]-1] == Obj.WALL or\n",
    "                    self.board[double_ahead[0]][double_ahead[1]-1] == Obj.WALL and \n",
    "                    self.board[double_ahead[0]+1][double_ahead[1]] == Obj.WALL):\n",
    "                    reward += Reward.DEADLOCK\n",
    "                \n",
    "                # Move the player.\n",
    "                next_player = tuple(ahead)\n",
    "                # Update box list\n",
    "                boxes = list(self.state[0])\n",
    "                boxes.remove(tuple(ahead))\n",
    "                boxes.append(tuple(double_ahead))\n",
    "                next_boxes = frozenset(boxes)\n",
    "                \n",
    "                next_state = (next_boxes, next_player)\n",
    "            else:\n",
    "                # Can't move because of the wall\n",
    "                reward += Reward.MOVE_TO_WALL\n",
    "        else:\n",
    "            # Can't move because of the wall\n",
    "            reward += Reward.MOVE_TO_WALL\n",
    "        \n",
    "        return next_state, reward\n",
    "    \n",
    "    def updateState(self, next_state):\n",
    "        boxes, player = self.state\n",
    "        for box in boxes:\n",
    "            self.board[box[0]][box[1]] -= Obj.BOX\n",
    "        self.board[player[0]][player[1]] -= Obj.PLAYER\n",
    "        \n",
    "        self.state = next_state\n",
    "        boxes, player = self.state\n",
    "        for box in boxes:\n",
    "            self.board[box[0]][box[1]] += Obj.BOX\n",
    "        self.board[player[0]][player[1]] += Obj.PLAYER\n",
    "\n",
    "    def getAction(self, eps):\n",
    "        if np.random.random_sample() < eps:\n",
    "            # Random move\n",
    "            action = np.random.randint(0, 4)\n",
    "        else:\n",
    "            # Pick the best action\n",
    "            action = np.argmax(self.Q[self.state])\n",
    "        return action\n",
    "    \n",
    "    def isFinished(self):\n",
    "        if self.state[0] == self.storages:\n",
    "            self.eps *= self.eps_decay_rate\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def visualize(self):\n",
    "        symbols = {\n",
    "            0: ' ',\n",
    "            1: '.',\n",
    "            2: '#',\n",
    "            3: '@',\n",
    "            4: '@',\n",
    "            5: '$',\n",
    "            6: '$'\n",
    "        }\n",
    "        for r in self.board:\n",
    "            print(''.join(map(lambda x:symbols[x], r)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab2f1438-5a5b-4c50-b73f-247918f01345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(input_file, alpha=1.0, gamma=1.0, max_iter=100000, eps=0.9, eps_decay_rate=0.9,printOpt=True):\n",
    "    \n",
    "    board_size, walls, boxes, storages, player = read_file(input_file)\n",
    "    max_step = board_size[0]*board_size[1]*len(boxes)\n",
    "    \n",
    "    solver = QLearning(board_size, walls, boxes, storages, player, max_step, eps, eps_decay_rate)\n",
    "\n",
    "    last_episode = \"\"\n",
    "    num_stalls = 0\n",
    "    num_iters_to_converge = -1\n",
    "    \n",
    "    #from tqdm import tqdm\n",
    "    for i in range(max_iter):#tqdm(range(max_iter)):\n",
    "        # Periodic evaluation for early stopping\n",
    "        if i % 100 == 0:\n",
    "            nsteps, episode = inference(solver)\n",
    "            if nsteps >= 0 and last_episode == episode:\n",
    "                num_stalls += 1\n",
    "            else:\n",
    "                num_stalls = 0\n",
    "            if num_stalls >= 5:\n",
    "                # Conclude the policy has converged if it stalls for 100 times\n",
    "                num_iters_to_converge = i\n",
    "                break\n",
    "            last_episode = episode\n",
    "        # Training\n",
    "        action = solver.getAction(solver.eps)\n",
    "        next_state, reward = solver.getNextState(action)\n",
    "        solver.Q[solver.state][action] = solver.Q[solver.state][action] + alpha*(reward + gamma*np.amax(solver.Q[next_state]) - solver.Q[solver.state][action])\n",
    "        solver.updateState(next_state)\n",
    "\n",
    "    length, episode = inference(solver, printOpt)\n",
    "    print(f\"# iters to converge: {num_iters_to_converge}\")\n",
    "    print(f\"# explored states: {len(solver.Q)}\")\n",
    "    print(f\"{length} {episode}\")\n",
    "    \n",
    "    return num_iters_to_converge, len(solver.Q), length, episode\n",
    "    \n",
    "def inference(solver, visualize=False):\n",
    "    eps = 0.0 # Greedy policy\n",
    "    orig_state = solver.state\n",
    "    solver.updateState(solver.init_state)\n",
    "    moves = []\n",
    "    len_moves, episode = -1, \"Failed finding goal\"\n",
    "    for i in range(solver.max_step):\n",
    "        action = solver.getAction(eps)\n",
    "        moves.append(solver.direction[action])\n",
    "        next_state, reward = solver.getNextState(action)\n",
    "        if visualize:\n",
    "            print(f\"best action: {solver.direction[action]}\")\n",
    "            print(solver.Q[solver.state])\n",
    "            solver.updateState(next_state)\n",
    "            solver.visualize()\n",
    "        else:\n",
    "            solver.updateState(next_state)\n",
    "        if solver.isFinished():\n",
    "            len_moves = len(moves)\n",
    "            episode = ''.join(moves)\n",
    "            break\n",
    "    \n",
    "    solver.updateState(orig_state)\n",
    "    return len_moves, episode\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41134b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def parameter_tuning(file_name='sokoban01.txt', tuning_step=3):\n",
    "    board_size, walls, boxes, storages, player = read_file(file_name)\n",
    "    max_step = board_size[0]*board_size[1]*len(boxes)\n",
    "    opt_a=[]\n",
    "    opt_g=[]\n",
    "    opt_eps_d=[]\n",
    "    total_performance=[]\n",
    "    for i in range(0,tuning_step):\n",
    "        performance = {}\n",
    "        for alpha in np.arange(0.2, 1.1, 0.2): #param alpha tuning from 0.2 to 1\n",
    "            for gamma in np.arange(0.2,1.1,0.2): #param gamma tuning from 0.2 to 1\n",
    "                for eps_decay_rate in np.arange(0.5,1,0.1): #param eps_decay_rate tuning from 0.5 to 1\n",
    "                    alpha = round(alpha,2) ;gamma = round(gamma,2) ; eps_decay_rate = round(eps_decay_rate,2)\n",
    "                    print(alpha,gamma,eps_decay_rate)\n",
    "                    num_step, len_q , len_move, _ = solve(file_name,alpha=alpha, gamma=gamma, eps_decay_rate=eps_decay_rate,printOpt=False)\n",
    "                    performance[alpha,gamma,eps_decay_rate] = [num_step, len_q, len_move]\n",
    "        total_performance.append(performance)\n",
    "        #sort valeus by length of episode first and then iteration number, only considering the converged case\n",
    "        opt_alpha, opt_gamma, opt_eps_decay_rate = [k for k, v in sorted(performance.items(), key=lambda item: (item[1][2],item[1][0],item[1][1])) if v[-1] != -1][0]\n",
    "        opt_a.append(opt_alpha)\n",
    "        opt_g.append(opt_gamma)\n",
    "        opt_eps_d.append(opt_eps_decay_rate)\n",
    "    return total_performance, opt_a, opt_g, opt_eps_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7028a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_param_tuning(file_path,performance,fixed_col,fixed_value):\n",
    "    col_name={'alpha':0,'gamma':1,'eps_decay rate':2}\n",
    "    col_id = {v:k for k,v in col_name.items() }\n",
    "    fixed_col_num= col_name[fixed_col]\n",
    "    check_col_x,check_col_y= [i for i in col_name.values() if i != fixed_col_num]\n",
    "    board_size, walls, boxes, storages, player = read_file(file_path)\n",
    "    max_step = board_size[0]*board_size[1]*len(boxes)\n",
    "    revised_perf = {k: v if v[0]!= -1 else [100000,v[1], max_step] for k, v in performance.items()}\n",
    "    \n",
    "    #normalize values\n",
    "    max_step = max([v[0] for v in revised_perf.values()]) ; min_step = min([v[0] for v in revised_perf.values()])\n",
    "    max_length = max([v[-1] for v in revised_perf.values()]); min_length = min([v[-1] for v in revised_perf.values()])\n",
    "    step = {k:(v[0]-min_step) /(max_step-min_step) for k,v in revised_perf.items() if k[fixed_col_num]==fixed_value}\n",
    "    length = {k: (v[-1]-min_length) /(max_length-min_length) for k,v in revised_perf.items() if k[fixed_col_num]==fixed_value}\n",
    "    g_e_relations ={}\n",
    "    for k in step.keys():\n",
    "        if k in g_e_relations:\n",
    "            g_e_relations[(k[check_col_x],k[check_col_y])] += 0.2 * step[k] + 0.8* length[k]\n",
    "        else:\n",
    "            g_e_relations[(k[check_col_x],k[check_col_y])] = 0.2* step[k] + 0.8* length[k]\n",
    "    x_range = [round(i*0.1,2) for i in np.arange(2,11,2)] \n",
    "    if fixed_col_num !=2 :\n",
    "        y_range = [round(i*0.1,2) for i in np.arange(5,10,1)] \n",
    "    else:\n",
    "        y_range = [round(i*0.1,2) for i in np.arange(2,11,2)]\n",
    "        \n",
    "    tr_auc = np.zeros((len(x_range),len(y_range)))\n",
    "    for i,k in enumerate(x_range):\n",
    "        for j,a in enumerate(y_range):\n",
    "            if g_e_relations[round(k,2),round(a,2)] == 1 :\n",
    "                tr_auc[i][j] = None\n",
    "            else:\n",
    "                tr_auc[i][j] = g_e_relations[round(k,2),round(a,2)]\n",
    "                \n",
    "    import matplotlib.pyplot as plt\n",
    "    f, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    cax = ax.matshow(tr_auc, interpolation='nearest')\n",
    "    f.colorbar(cax)\n",
    "    ax.set_xlabel(f'{col_id[check_col_x]} values')\n",
    "    ax.set_ylabel(f'{col_id[check_col_y]} values')\n",
    "    ax.set_xticklabels(['']+list(x_range))\n",
    "    ax.set_yticklabels(['']+list(y_range))\n",
    "    plt.title(f\"Performance of each {col_id[check_col_x]} and {col_id[check_col_y]} values\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e036724a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.2 0.5\n",
      "# iters to converge: 90100\n",
      "# explored states: 1709\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.2 0.2 0.6\n",
      "# iters to converge: -1\n",
      "# explored states: 2429\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.7\n",
      "# iters to converge: -1\n",
      "# explored states: 2194\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 2590\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2750\n",
      "-1 Failed finding goal\n",
      "0.2 0.4 0.5\n",
      "# iters to converge: 72000\n",
      "# explored states: 1917\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.2 0.4 0.6\n",
      "# iters to converge: 80100\n",
      "# explored states: 2006\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.2 0.4 0.7\n",
      "# iters to converge: -1\n",
      "# explored states: 2706\n",
      "-1 Failed finding goal\n",
      "0.2 0.4 0.8\n",
      "# iters to converge: 96800\n",
      "# explored states: 2626\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.4 0.9\n",
      "# iters to converge: 81300\n",
      "# explored states: 2199\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 0.6 0.5\n",
      "# iters to converge: 98600\n",
      "# explored states: 2401\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 0.6 0.6\n",
      "# iters to converge: -1\n",
      "# explored states: 2643\n",
      "-1 Failed finding goal\n",
      "0.2 0.6 0.7\n",
      "# iters to converge: 67400\n",
      "# explored states: 1823\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.2 0.6 0.8\n",
      "# iters to converge: 60700\n",
      "# explored states: 1776\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.2 0.6 0.9\n",
      "# iters to converge: 78500\n",
      "# explored states: 2280\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.8 0.5\n",
      "# iters to converge: 59000\n",
      "# explored states: 1935\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.2 0.8 0.6\n",
      "# iters to converge: 73500\n",
      "# explored states: 2303\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.2 0.8 0.7\n",
      "# iters to converge: 53700\n",
      "# explored states: 1686\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.8 0.8\n",
      "# iters to converge: 77100\n",
      "# explored states: 2321\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.2 0.8 0.9\n",
      "# iters to converge: 82700\n",
      "# explored states: 2354\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.2 1.0 0.5\n",
      "# iters to converge: 64200\n",
      "# explored states: 2500\n",
      "22 ULLLRURUULLLDLUDRDDLDR\n",
      "0.2 1.0 0.6\n",
      "# iters to converge: 60800\n",
      "# explored states: 2522\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.7\n",
      "# iters to converge: 46300\n",
      "# explored states: 2062\n",
      "22 ULLLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.8\n",
      "# iters to converge: 41600\n",
      "# explored states: 1970\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.9\n",
      "# iters to converge: 47000\n",
      "# explored states: 2317\n",
      "22 ULLLRURUULLLDLURDDDLDR\n",
      "0.4 0.2 0.5\n",
      "# iters to converge: 49600\n",
      "# explored states: 1581\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.2 0.6\n",
      "# iters to converge: 53600\n",
      "# explored states: 1742\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.2 0.7\n",
      "# iters to converge: 74000\n",
      "# explored states: 2261\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.2 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 2642\n",
      "-1 Failed finding goal\n",
      "0.4 0.2 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2698\n",
      "-1 Failed finding goal\n",
      "0.4 0.4 0.5\n",
      "# iters to converge: 89500\n",
      "# explored states: 2470\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.4 0.4 0.6\n",
      "# iters to converge: 39400\n",
      "# explored states: 1566\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.4 0.7\n",
      "# iters to converge: 51000\n",
      "# explored states: 1879\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.4 0.4 0.8\n",
      "# iters to converge: 63500\n",
      "# explored states: 2234\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.4 0.4 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 658\n",
      "-1 Failed finding goal\n",
      "0.4 0.6 0.5\n",
      "# iters to converge: 68600\n",
      "# explored states: 2189\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.6 0.6\n",
      "# iters to converge: 55600\n",
      "# explored states: 1985\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 0.6 0.7\n",
      "# iters to converge: 45100\n",
      "# explored states: 1910\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.4 0.6 0.8\n",
      "# iters to converge: 56700\n",
      "# explored states: 2188\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.6 0.9\n",
      "# iters to converge: 51400\n",
      "# explored states: 2249\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.4 0.8 0.5\n",
      "# iters to converge: 32700\n",
      "# explored states: 1590\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.8 0.6\n",
      "# iters to converge: 58700\n",
      "# explored states: 1988\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.4 0.8 0.7\n",
      "# iters to converge: 72100\n",
      "# explored states: 2163\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.8 0.8\n",
      "# iters to converge: 71200\n",
      "# explored states: 2190\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.4 0.8 0.9\n",
      "# iters to converge: 39900\n",
      "# explored states: 1774\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.4 1.0 0.5\n",
      "# iters to converge: 69400\n",
      "# explored states: 2630\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.6\n",
      "# iters to converge: 32000\n",
      "# explored states: 1836\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.4 1.0 0.7\n",
      "# iters to converge: 33900\n",
      "# explored states: 1895\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.8\n",
      "# iters to converge: 68800\n",
      "# explored states: 2161\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.4 1.0 0.9\n",
      "# iters to converge: 55000\n",
      "# explored states: 2182\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 0.2 0.5\n",
      "# iters to converge: -1\n",
      "# explored states: 62\n",
      "-1 Failed finding goal\n",
      "0.6 0.2 0.6\n",
      "# iters to converge: 38600\n",
      "# explored states: 1747\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.2 0.7\n",
      "# iters to converge: 53100\n",
      "# explored states: 2215\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.2 0.8\n",
      "# iters to converge: 58500\n",
      "# explored states: 2147\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.2 0.9\n",
      "# iters to converge: 94400\n",
      "# explored states: 2573\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.6 0.4 0.5\n",
      "# iters to converge: 42700\n",
      "# explored states: 1834\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.6 0.4 0.6\n",
      "# iters to converge: 32700\n",
      "# explored states: 1713\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.4 0.7\n",
      "# iters to converge: 34800\n",
      "# explored states: 1642\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.4 0.8\n",
      "# iters to converge: 66000\n",
      "# explored states: 2287\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.6 0.4 0.9\n",
      "# iters to converge: 53800\n",
      "# explored states: 2156\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.6 0.5\n",
      "# iters to converge: 28000\n",
      "# explored states: 1557\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.6 0.6\n",
      "# iters to converge: 27800\n",
      "# explored states: 1351\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.6 0.7\n",
      "# iters to converge: 66400\n",
      "# explored states: 2167\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.6 0.8\n",
      "# iters to converge: 60300\n",
      "# explored states: 2099\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.6 0.9\n",
      "# iters to converge: 83500\n",
      "# explored states: 2529\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.8 0.5\n",
      "# iters to converge: 28900\n",
      "# explored states: 1350\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.6 0.8 0.6\n",
      "# iters to converge: 42800\n",
      "# explored states: 1742\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.8 0.7\n",
      "# iters to converge: 28100\n",
      "# explored states: 1347\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.8 0.8\n",
      "# iters to converge: 31900\n",
      "# explored states: 1581\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.6 0.8 0.9\n",
      "# iters to converge: 92400\n",
      "# explored states: 2624\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 1.0 0.5\n",
      "# iters to converge: 51200\n",
      "# explored states: 2474\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.6\n",
      "# iters to converge: 35900\n",
      "# explored states: 1935\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.6 1.0 0.7\n",
      "# iters to converge: 63600\n",
      "# explored states: 2384\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.8\n",
      "# iters to converge: 27100\n",
      "# explored states: 1902\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 344\n",
      "-1 Failed finding goal\n",
      "0.8 0.2 0.5\n",
      "# iters to converge: 28800\n",
      "# explored states: 1508\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.8 0.2 0.6\n",
      "# iters to converge: 46600\n",
      "# explored states: 1993\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.2 0.7\n",
      "# iters to converge: 29300\n",
      "# explored states: 1434\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.2 0.8\n",
      "# iters to converge: 51700\n",
      "# explored states: 2335\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.2 0.9\n",
      "# iters to converge: 74900\n",
      "# explored states: 2460\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.4 0.5\n",
      "# iters to converge: 37000\n",
      "# explored states: 1840\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.4 0.6\n",
      "# iters to converge: 34200\n",
      "# explored states: 1841\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.4 0.7\n",
      "# iters to converge: 30200\n",
      "# explored states: 1725\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.8 0.4 0.8\n",
      "# iters to converge: 71100\n",
      "# explored states: 2384\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.8 0.4 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# iters to converge: 51100\n",
      "# explored states: 1985\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.6 0.5\n",
      "# iters to converge: 42000\n",
      "# explored states: 1876\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.8 0.6 0.6\n",
      "# iters to converge: 71900\n",
      "# explored states: 2270\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.6 0.7\n",
      "# iters to converge: 28100\n",
      "# explored states: 1605\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.6 0.8\n",
      "# iters to converge: 26300\n",
      "# explored states: 1479\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.6 0.9\n",
      "# iters to converge: 46800\n",
      "# explored states: 2149\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.8 0.8 0.5\n",
      "# iters to converge: 26600\n",
      "# explored states: 1788\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.8 0.6\n",
      "# iters to converge: 39400\n",
      "# explored states: 1893\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.8 0.8 0.7\n",
      "# iters to converge: 31400\n",
      "# explored states: 1644\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.8 0.8 0.8\n",
      "# iters to converge: 57200\n",
      "# explored states: 2168\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.8 0.8 0.9\n",
      "# iters to converge: 48200\n",
      "# explored states: 1923\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.8 1.0 0.5\n",
      "# iters to converge: 28800\n",
      "# explored states: 1899\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.6\n",
      "# iters to converge: 45800\n",
      "# explored states: 1842\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.8 1.0 0.7\n",
      "# iters to converge: 37000\n",
      "# explored states: 1980\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.8 1.0 0.8\n",
      "# iters to converge: 66600\n",
      "# explored states: 2229\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.9\n",
      "# iters to converge: 30900\n",
      "# explored states: 1618\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "1.0 0.2 0.5\n",
      "# iters to converge: 20700\n",
      "# explored states: 1511\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "1.0 0.2 0.6\n",
      "# iters to converge: 44300\n",
      "# explored states: 1980\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.2 0.7\n",
      "# iters to converge: 77500\n",
      "# explored states: 2579\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.2 0.8\n",
      "# iters to converge: 21400\n",
      "# explored states: 1453\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.2 0.9\n",
      "# iters to converge: 35500\n",
      "# explored states: 1917\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.5\n",
      "# iters to converge: 30400\n",
      "# explored states: 1690\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.6\n",
      "# iters to converge: 24900\n",
      "# explored states: 1551\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.4 0.7\n",
      "# iters to converge: 23100\n",
      "# explored states: 1331\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.8\n",
      "# iters to converge: 22900\n",
      "# explored states: 1517\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.9\n",
      "# iters to converge: 53500\n",
      "# explored states: 2203\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "1.0 0.6 0.5\n",
      "# iters to converge: 18500\n",
      "# explored states: 1138\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.6 0.6\n",
      "# iters to converge: 44700\n",
      "# explored states: 1781\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.6 0.7\n",
      "# iters to converge: 34800\n",
      "# explored states: 1734\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "1.0 0.6 0.8\n",
      "# iters to converge: 32900\n",
      "# explored states: 1945\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.6 0.9\n",
      "# iters to converge: 59200\n",
      "# explored states: 2240\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.8 0.5\n",
      "# iters to converge: 17100\n",
      "# explored states: 1264\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 0.8 0.6\n",
      "# iters to converge: 38400\n",
      "# explored states: 1775\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.8 0.7\n",
      "# iters to converge: 23700\n",
      "# explored states: 1373\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 0.8 0.8\n",
      "# iters to converge: 43600\n",
      "# explored states: 1990\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.8 0.9\n",
      "# iters to converge: 56100\n",
      "# explored states: 2046\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 1.0 0.5\n",
      "# iters to converge: 24100\n",
      "# explored states: 1987\n",
      "24 LULLRURUULLLRDLLURDDDLDR\n",
      "1.0 1.0 0.6\n",
      "# iters to converge: 36800\n",
      "# explored states: 2285\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.7\n",
      "# iters to converge: 18500\n",
      "# explored states: 1475\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.8\n",
      "# iters to converge: 30900\n",
      "# explored states: 1819\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.9\n",
      "# iters to converge: 65000\n",
      "# explored states: 2449\n",
      "27 LULURDLLRURUULLLDDDLDRUUULU\n",
      "0.2 0.2 0.5\n",
      "# iters to converge: 98200\n",
      "# explored states: 2040\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.2 0.2 0.6\n",
      "# iters to converge: -1\n",
      "# explored states: 2504\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.7\n",
      "# iters to converge: -1\n",
      "# explored states: 2510\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 2393\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2479\n",
      "-1 Failed finding goal\n",
      "0.2 0.4 0.5\n",
      "# iters to converge: -1\n",
      "# explored states: 2523\n",
      "-1 Failed finding goal\n",
      "0.2 0.4 0.6\n",
      "# iters to converge: 95500\n",
      "# explored states: 2154\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.2 0.4 0.7\n",
      "# iters to converge: -1\n",
      "# explored states: 2350\n",
      "-1 Failed finding goal\n",
      "0.2 0.4 0.8\n",
      "# iters to converge: 74200\n",
      "# explored states: 1898\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 0.4 0.9\n",
      "# iters to converge: 91500\n",
      "# explored states: 2646\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.2 0.6 0.5\n",
      "# iters to converge: -1\n",
      "# explored states: 2454\n",
      "-1 Failed finding goal\n",
      "0.2 0.6 0.6\n",
      "# iters to converge: 54000\n",
      "# explored states: 1686\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.6 0.7\n",
      "# iters to converge: 86600\n",
      "# explored states: 2151\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 0.6 0.8\n",
      "# iters to converge: 74500\n",
      "# explored states: 2359\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.2 0.6 0.9\n",
      "# iters to converge: 98900\n",
      "# explored states: 2567\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.2 0.8 0.5\n",
      "# iters to converge: 50700\n",
      "# explored states: 1631\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.2 0.8 0.6\n",
      "# iters to converge: 85700\n",
      "# explored states: 2332\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.2 0.8 0.7\n",
      "# iters to converge: 69500\n",
      "# explored states: 2141\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.2 0.8 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 2647\n",
      "-1 Failed finding goal\n",
      "0.2 0.8 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2832\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.2 1.0 0.5\n",
      "# iters to converge: 55400\n",
      "# explored states: 2252\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.6\n",
      "# iters to converge: -1\n",
      "# explored states: 1287\n",
      "-1 Failed finding goal\n",
      "0.2 1.0 0.7\n",
      "# iters to converge: 70400\n",
      "# explored states: 2586\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.8\n",
      "# iters to converge: 57700\n",
      "# explored states: 2317\n",
      "22 ULLLRURUULLLDLUDRDDLDR\n",
      "0.2 1.0 0.9\n",
      "# iters to converge: 82700\n",
      "# explored states: 2845\n",
      "22 ULLLRURUULLLDLUDRDDLDR\n",
      "0.4 0.2 0.5\n",
      "# iters to converge: 85300\n",
      "# explored states: 2351\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.4 0.2 0.6\n",
      "# iters to converge: 56300\n",
      "# explored states: 1816\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.2 0.7\n",
      "# iters to converge: 61600\n",
      "# explored states: 2061\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.2 0.8\n",
      "# iters to converge: 87000\n",
      "# explored states: 2530\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 0.2 0.9\n",
      "# iters to converge: 84100\n",
      "# explored states: 2351\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.4 0.5\n",
      "# iters to converge: 49800\n",
      "# explored states: 1886\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.4 0.6\n",
      "# iters to converge: 88000\n",
      "# explored states: 2506\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.4 0.7\n",
      "# iters to converge: 94700\n",
      "# explored states: 2742\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 0.4 0.8\n",
      "# iters to converge: 45500\n",
      "# explored states: 1744\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.4 0.9\n",
      "# iters to converge: 79300\n",
      "# explored states: 2597\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.6 0.5\n",
      "# iters to converge: 49500\n",
      "# explored states: 1937\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.6 0.6\n",
      "# iters to converge: 44900\n",
      "# explored states: 1927\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 0.6 0.7\n",
      "# iters to converge: 67700\n",
      "# explored states: 2116\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 0.6 0.8\n",
      "# iters to converge: 59300\n",
      "# explored states: 2177\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.4 0.6 0.9\n",
      "# iters to converge: 51800\n",
      "# explored states: 1912\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.4 0.8 0.5\n",
      "# iters to converge: 36700\n",
      "# explored states: 1639\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.4 0.8 0.6\n",
      "# iters to converge: 40400\n",
      "# explored states: 1614\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.4 0.8 0.7\n",
      "# iters to converge: 31800\n",
      "# explored states: 1499\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.4 0.8 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# iters to converge: 89000\n",
      "# explored states: 2295\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.8 0.9\n",
      "# iters to converge: 45500\n",
      "# explored states: 1940\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.4 1.0 0.5\n",
      "# iters to converge: -1\n",
      "# explored states: 139\n",
      "-1 Failed finding goal\n",
      "0.4 1.0 0.6\n",
      "# iters to converge: 29100\n",
      "# explored states: 1739\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.7\n",
      "# iters to converge: 30300\n",
      "# explored states: 1961\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.8\n",
      "# iters to converge: 38600\n",
      "# explored states: 1998\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.9\n",
      "# iters to converge: 68500\n",
      "# explored states: 2238\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 0.2 0.5\n",
      "# iters to converge: 72700\n",
      "# explored states: 2325\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.2 0.6\n",
      "# iters to converge: 39600\n",
      "# explored states: 1790\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.6 0.2 0.7\n",
      "# iters to converge: 37400\n",
      "# explored states: 1712\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.6 0.2 0.8\n",
      "# iters to converge: 68500\n",
      "# explored states: 2236\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.2 0.9\n",
      "# iters to converge: 89500\n",
      "# explored states: 2470\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.4 0.5\n",
      "# iters to converge: 29000\n",
      "# explored states: 1482\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.6 0.4 0.6\n",
      "# iters to converge: 47300\n",
      "# explored states: 1984\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.4 0.7\n",
      "# iters to converge: 28700\n",
      "# explored states: 1473\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.6 0.4 0.8\n",
      "# iters to converge: 33800\n",
      "# explored states: 1567\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.4 0.9\n",
      "# iters to converge: 40500\n",
      "# explored states: 1866\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.6 0.6 0.5\n",
      "# iters to converge: 45100\n",
      "# explored states: 1856\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.6 0.6\n",
      "# iters to converge: 28800\n",
      "# explored states: 1353\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.6 0.7\n",
      "# iters to converge: 38900\n",
      "# explored states: 1590\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.6 0.8\n",
      "# iters to converge: 74100\n",
      "# explored states: 2385\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.6 0.6 0.9\n",
      "# iters to converge: 48900\n",
      "# explored states: 2035\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.6 0.8 0.5\n",
      "# iters to converge: 39600\n",
      "# explored states: 1670\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.6 0.8 0.6\n",
      "# iters to converge: 55000\n",
      "# explored states: 1964\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.6 0.8 0.7\n",
      "# iters to converge: 31000\n",
      "# explored states: 1466\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.8 0.8\n",
      "# iters to converge: 32600\n",
      "# explored states: 1623\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.8 0.9\n",
      "# iters to converge: 79500\n",
      "# explored states: 2409\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 1.0 0.5\n",
      "# iters to converge: 21600\n",
      "# explored states: 1585\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.6 1.0 0.6\n",
      "# iters to converge: 44600\n",
      "# explored states: 2278\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.6 1.0 0.7\n",
      "# iters to converge: 71400\n",
      "# explored states: 2218\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.8\n",
      "# iters to converge: 43500\n",
      "# explored states: 1955\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.9\n",
      "# iters to converge: 34600\n",
      "# explored states: 1965\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 0.2 0.5\n",
      "# iters to converge: 24400\n",
      "# explored states: 1293\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.2 0.6\n",
      "# iters to converge: 68300\n",
      "# explored states: 2221\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.8 0.2 0.7\n",
      "# iters to converge: -1\n",
      "# explored states: 175\n",
      "-1 Failed finding goal\n",
      "0.8 0.2 0.8\n",
      "# iters to converge: 74200\n",
      "# explored states: 2456\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.2 0.9\n",
      "# iters to converge: 59400\n",
      "# explored states: 2224\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.8 0.4 0.5\n",
      "# iters to converge: 58000\n",
      "# explored states: 2209\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.4 0.6\n",
      "# iters to converge: 23500\n",
      "# explored states: 1373\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.8 0.4 0.7\n",
      "# iters to converge: 37200\n",
      "# explored states: 1702\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.4 0.8\n",
      "# iters to converge: 49600\n",
      "# explored states: 1985\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.4 0.9\n",
      "# iters to converge: 78000\n",
      "# explored states: 2500\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.8 0.6 0.5\n",
      "# iters to converge: 28000\n",
      "# explored states: 1354\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.8 0.6 0.6\n",
      "# iters to converge: 31600\n",
      "# explored states: 1439\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.6 0.7\n",
      "# iters to converge: 29000\n",
      "# explored states: 1521\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.8 0.6 0.8\n",
      "# iters to converge: 57500\n",
      "# explored states: 2264\n",
      "40 ULLURUULLLDLURRRRDDDLLDLURRRUUULLDLDDLDR\n",
      "0.8 0.6 0.9\n",
      "# iters to converge: 40400\n",
      "# explored states: 1886\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.8 0.5\n",
      "# iters to converge: 73400\n",
      "# explored states: 2343\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.8 0.8 0.6\n",
      "# iters to converge: 26200\n",
      "# explored states: 1418\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.8 0.8 0.7\n",
      "# iters to converge: 30900\n",
      "# explored states: 1563\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.8 0.8 0.8\n",
      "# iters to converge: 42900\n",
      "# explored states: 1836\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.8 0.8 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 765\n",
      "-1 Failed finding goal\n",
      "0.8 1.0 0.5\n",
      "# iters to converge: 17700\n",
      "# explored states: 1597\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.6\n",
      "# iters to converge: 17500\n",
      "# explored states: 1558\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.7\n",
      "# iters to converge: 29300\n",
      "# explored states: 2077\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 823\n",
      "-1 Failed finding goal\n",
      "0.8 1.0 0.9\n",
      "# iters to converge: 32900\n",
      "# explored states: 1504\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "1.0 0.2 0.5\n",
      "# iters to converge: 47200\n",
      "# explored states: 2036\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.2 0.6\n",
      "# iters to converge: 22600\n",
      "# explored states: 1229\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 0.2 0.7\n",
      "# iters to converge: 80700\n",
      "# explored states: 2570\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.2 0.8\n",
      "# iters to converge: 46800\n",
      "# explored states: 2106\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 0.2 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 433\n",
      "-1 Failed finding goal\n",
      "1.0 0.4 0.5\n",
      "# iters to converge: 19500\n",
      "# explored states: 1073\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.6\n",
      "# iters to converge: 59800\n",
      "# explored states: 2095\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.7\n",
      "# iters to converge: 81900\n",
      "# explored states: 2707\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.8\n",
      "# iters to converge: 57000\n",
      "# explored states: 2256\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "1.0 0.4 0.9\n",
      "# iters to converge: 54400\n",
      "# explored states: 2238\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.6 0.5\n",
      "# iters to converge: 45300\n",
      "# explored states: 2013\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "1.0 0.6 0.6\n",
      "# iters to converge: 48500\n",
      "# explored states: 2073\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.6 0.7\n",
      "# iters to converge: 44000\n",
      "# explored states: 1856\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "1.0 0.6 0.8\n",
      "# iters to converge: 58200\n",
      "# explored states: 2206\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.6 0.9\n",
      "# iters to converge: 36200\n",
      "# explored states: 1986\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.8 0.5\n",
      "# iters to converge: 16900\n",
      "# explored states: 1255\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.8 0.6\n",
      "# iters to converge: 37200\n",
      "# explored states: 1626\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 0.8 0.7\n",
      "# iters to converge: 60100\n",
      "# explored states: 2219\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 0.8 0.8\n",
      "# iters to converge: 55700\n",
      "# explored states: 2114\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.8 0.9\n",
      "# iters to converge: 54200\n",
      "# explored states: 2145\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "1.0 1.0 0.5\n",
      "# iters to converge: 57500\n",
      "# explored states: 1948\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "1.0 1.0 0.6\n",
      "# iters to converge: 46400\n",
      "# explored states: 2053\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "1.0 1.0 0.7\n",
      "# iters to converge: 43300\n",
      "# explored states: 1769\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.8\n",
      "# iters to converge: 28700\n",
      "# explored states: 1815\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.9\n",
      "# iters to converge: 54000\n",
      "# explored states: 1882\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.2 0.2 0.5\n",
      "# iters to converge: -1\n",
      "# explored states: 1971\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.2 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# iters to converge: -1\n",
      "# explored states: 2114\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.7\n",
      "# iters to converge: -1\n",
      "# explored states: 2139\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 0.2 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 2498\n",
      "-1 Failed finding goal\n",
      "0.2 0.2 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2505\n",
      "-1 Failed finding goal\n",
      "0.2 0.4 0.5\n",
      "# iters to converge: 78500\n",
      "# explored states: 2018\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.4 0.6\n",
      "# iters to converge: 89900\n",
      "# explored states: 2344\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 0.4 0.7\n",
      "# iters to converge: 86500\n",
      "# explored states: 2025\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.2 0.4 0.8\n",
      "# iters to converge: 93000\n",
      "# explored states: 2426\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 0.4 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2578\n",
      "-1 Failed finding goal\n",
      "0.2 0.6 0.5\n",
      "# iters to converge: -1\n",
      "# explored states: 2431\n",
      "-1 Failed finding goal\n",
      "0.2 0.6 0.6\n",
      "# iters to converge: 57700\n",
      "# explored states: 1695\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.2 0.6 0.7\n",
      "# iters to converge: 73500\n",
      "# explored states: 2032\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.2 0.6 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 2699\n",
      "-1 Failed finding goal\n",
      "0.2 0.6 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2808\n",
      "-1 Failed finding goal\n",
      "0.2 0.8 0.5\n",
      "# iters to converge: 70700\n",
      "# explored states: 2248\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.2 0.8 0.6\n",
      "# iters to converge: 60000\n",
      "# explored states: 1857\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.2 0.8 0.7\n",
      "# iters to converge: 63800\n",
      "# explored states: 2081\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.2 0.8 0.8\n",
      "# iters to converge: 69700\n",
      "# explored states: 2129\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.2 0.8 0.9\n",
      "# iters to converge: 65000\n",
      "# explored states: 2196\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.2 1.0 0.5\n",
      "# iters to converge: 51700\n",
      "# explored states: 2215\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.6\n",
      "# iters to converge: 43500\n",
      "# explored states: 2006\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.7\n",
      "# iters to converge: 42700\n",
      "# explored states: 2026\n",
      "22 ULLLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.8\n",
      "# iters to converge: 56300\n",
      "# explored states: 2424\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.2 1.0 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 622\n",
      "-1 Failed finding goal\n",
      "0.4 0.2 0.5\n",
      "# iters to converge: 51000\n",
      "# explored states: 1727\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 0.2 0.6\n",
      "# iters to converge: -1\n",
      "# explored states: 2677\n",
      "-1 Failed finding goal\n",
      "0.4 0.2 0.7\n",
      "# iters to converge: 77500\n",
      "# explored states: 2209\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 0.2 0.8\n",
      "# iters to converge: 97400\n",
      "# explored states: 2492\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.4 0.2 0.9\n",
      "# iters to converge: 90100\n",
      "# explored states: 2754\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.4 0.5\n",
      "# iters to converge: 72900\n",
      "# explored states: 2177\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.4 0.4 0.6\n",
      "# iters to converge: 39900\n",
      "# explored states: 1569\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.4 0.4 0.7\n",
      "# iters to converge: 49500\n",
      "# explored states: 2022\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.4 0.8\n",
      "# iters to converge: 53300\n",
      "# explored states: 1975\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.4 0.4 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 2616\n",
      "-1 Failed finding goal\n",
      "0.4 0.6 0.5\n",
      "# iters to converge: 73300\n",
      "# explored states: 2301\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.6 0.6\n",
      "# iters to converge: 34300\n",
      "# explored states: 1539\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.4 0.6 0.7\n",
      "# iters to converge: 34300\n",
      "# explored states: 1497\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.6 0.8\n",
      "# iters to converge: 74100\n",
      "# explored states: 2138\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.4 0.6 0.9\n",
      "# iters to converge: 81600\n",
      "# explored states: 2650\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.8 0.5\n",
      "# iters to converge: 36700\n",
      "# explored states: 1667\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.4 0.8 0.6\n",
      "# iters to converge: 40800\n",
      "# explored states: 1799\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.4 0.8 0.7\n",
      "# iters to converge: 40100\n",
      "# explored states: 1779\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.4 0.8 0.8\n",
      "# iters to converge: 37100\n",
      "# explored states: 1750\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.4 0.8 0.9\n",
      "# iters to converge: 68200\n",
      "# explored states: 2151\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.4 1.0 0.5\n",
      "# iters to converge: -1\n",
      "# explored states: 1725\n",
      "-1 Failed finding goal\n",
      "0.4 1.0 0.6\n",
      "# iters to converge: 61100\n",
      "# explored states: 2142\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.4 1.0 0.7\n",
      "# iters to converge: 25500\n",
      "# explored states: 1679\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.8\n",
      "# iters to converge: 36700\n",
      "# explored states: 2018\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.4 1.0 0.9\n",
      "# iters to converge: 33000\n",
      "# explored states: 1867\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 0.2 0.5\n",
      "# iters to converge: 66200\n",
      "# explored states: 2240\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.6 0.2 0.6\n",
      "# iters to converge: 77400\n",
      "# explored states: 2293\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.2 0.7\n",
      "# iters to converge: 67300\n",
      "# explored states: 2247\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.6 0.2 0.8\n",
      "# iters to converge: 59200\n",
      "# explored states: 2129\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.6 0.2 0.9\n",
      "# iters to converge: 58000\n",
      "# explored states: 2047\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.4 0.5\n",
      "# iters to converge: 89300\n",
      "# explored states: 2422\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.6 0.4 0.6\n",
      "# iters to converge: 32900\n",
      "# explored states: 1573\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.4 0.7\n",
      "# iters to converge: 46100\n",
      "# explored states: 1959\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.4 0.8\n",
      "# iters to converge: -1\n",
      "# explored states: 877\n",
      "-1 Failed finding goal\n",
      "0.6 0.4 0.9\n",
      "# iters to converge: 56900\n",
      "# explored states: 2240\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.6 0.6 0.5\n",
      "# iters to converge: 35700\n",
      "# explored states: 1690\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.6 0.6 0.6\n",
      "# iters to converge: 26700\n",
      "# explored states: 1387\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.6 0.6 0.7\n",
      "# iters to converge: 39700\n",
      "# explored states: 1972\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "0.6 0.6 0.8\n",
      "# iters to converge: 49600\n",
      "# explored states: 2050\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.6 0.9\n",
      "# iters to converge: 59400\n",
      "# explored states: 2252\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.6 0.8 0.5\n",
      "# iters to converge: 32800\n",
      "# explored states: 1486\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.6 0.8 0.6\n",
      "# iters to converge: 28200\n",
      "# explored states: 1319\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.6 0.8 0.7\n",
      "# iters to converge: 31300\n",
      "# explored states: 1593\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.6 0.8 0.8\n",
      "# iters to converge: 39000\n",
      "# explored states: 1701\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 0.8 0.9\n",
      "# iters to converge: 82500\n",
      "# explored states: 2324\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.6 1.0 0.5\n",
      "# iters to converge: 28200\n",
      "# explored states: 1800\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.6 1.0 0.6\n",
      "# iters to converge: 24600\n",
      "# explored states: 1475\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.7\n",
      "# iters to converge: 22300\n",
      "# explored states: 1773\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.6 1.0 0.8\n",
      "# iters to converge: 30200\n",
      "# explored states: 1761\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.6 1.0 0.9\n",
      "# iters to converge: 21000\n",
      "# explored states: 1587\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.8 0.2 0.5\n",
      "# iters to converge: 40500\n",
      "# explored states: 1861\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.8 0.2 0.6\n",
      "# iters to converge: 27300\n",
      "# explored states: 1426\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.8 0.2 0.7\n",
      "# iters to converge: -1\n",
      "# explored states: 969\n",
      "-1 Failed finding goal\n",
      "0.8 0.2 0.8\n",
      "# iters to converge: 69100\n",
      "# explored states: 2268\n",
      "36 LULURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.2 0.9\n",
      "# iters to converge: 43700\n",
      "# explored states: 2075\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "0.8 0.4 0.5\n",
      "# iters to converge: 33100\n",
      "# explored states: 1767\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.8 0.4 0.6\n",
      "# iters to converge: 69000\n",
      "# explored states: 2294\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.4 0.7\n",
      "# iters to converge: 29800\n",
      "# explored states: 1577\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.4 0.8\n",
      "# iters to converge: 45400\n",
      "# explored states: 2106\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.4 0.9\n",
      "# iters to converge: -1\n",
      "# explored states: 825\n",
      "-1 Failed finding goal\n",
      "0.8 0.6 0.5\n",
      "# iters to converge: 26200\n",
      "# explored states: 1515\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 0.6 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# iters to converge: 34400\n",
      "# explored states: 1600\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.6 0.7\n",
      "# iters to converge: 18100\n",
      "# explored states: 1179\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "0.8 0.6 0.8\n",
      "# iters to converge: 78400\n",
      "# explored states: 2406\n",
      "36 ULLURUULLLDLURRRRDDLDLRRUUULLDLDDLDR\n",
      "0.8 0.6 0.9\n",
      "# iters to converge: 49000\n",
      "# explored states: 1955\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "0.8 0.8 0.5\n",
      "# iters to converge: 29100\n",
      "# explored states: 1530\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "0.8 0.8 0.6\n",
      "# iters to converge: 30500\n",
      "# explored states: 1425\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.8 0.7\n",
      "# iters to converge: 24600\n",
      "# explored states: 1401\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLLDDDLDR\n",
      "0.8 0.8 0.8\n",
      "# iters to converge: 56600\n",
      "# explored states: 1990\n",
      "40 ULLURUULLLDLURRRRDDLDLDLURRURUULLLDDDLDR\n",
      "0.8 0.8 0.9\n",
      "# iters to converge: 56600\n",
      "# explored states: 2131\n",
      "36 ULLURUULLLDLURRRRDDDLLRRUUULLDLDDLDR\n",
      "0.8 1.0 0.5\n",
      "# iters to converge: 41600\n",
      "# explored states: 1870\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.6\n",
      "# iters to converge: 22300\n",
      "# explored states: 1760\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.7\n",
      "# iters to converge: 49200\n",
      "# explored states: 1999\n",
      "22 LULLRURUULLLDLUDRDDLDR\n",
      "0.8 1.0 0.8\n",
      "# iters to converge: 23900\n",
      "# explored states: 1550\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "0.8 1.0 0.9\n",
      "# iters to converge: 32200\n",
      "# explored states: 1707\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 0.2 0.5\n",
      "# iters to converge: 20500\n",
      "# explored states: 1303\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.2 0.6\n",
      "# iters to converge: 35700\n",
      "# explored states: 1764\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.2 0.7\n",
      "# iters to converge: 27100\n",
      "# explored states: 1845\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.2 0.8\n",
      "# iters to converge: 61400\n",
      "# explored states: 2297\n",
      "36 LULURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.2 0.9\n",
      "# iters to converge: 41400\n",
      "# explored states: 2053\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.5\n",
      "# iters to converge: 61000\n",
      "# explored states: 2274\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.6\n",
      "# iters to converge: 23800\n",
      "# explored states: 1409\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.4 0.7\n",
      "# iters to converge: 59200\n",
      "# explored states: 2318\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.8\n",
      "# iters to converge: 29300\n",
      "# explored states: 1454\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.4 0.9\n",
      "# iters to converge: 41600\n",
      "# explored states: 2086\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "1.0 0.6 0.5\n",
      "# iters to converge: 22900\n",
      "# explored states: 1270\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.6 0.6\n",
      "# iters to converge: 21400\n",
      "# explored states: 1196\n",
      "40 ULLURUULLLDLURRRRDDLDLDLURRRUUULLDLDDLDR\n",
      "1.0 0.6 0.7\n",
      "# iters to converge: 27600\n",
      "# explored states: 1664\n",
      "40 ULLURUULLLDLURRRRDDLDLDLURRURUULLDLDDLDR\n",
      "1.0 0.6 0.8\n",
      "# iters to converge: 24400\n",
      "# explored states: 1452\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 0.6 0.9\n",
      "# iters to converge: 34300\n",
      "# explored states: 1684\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.8 0.5\n",
      "# iters to converge: 17600\n",
      "# explored states: 1117\n",
      "36 ULLURUULLLDLURRRRDDLDLRURUULLLDDDLDR\n",
      "1.0 0.8 0.6\n",
      "# iters to converge: 43000\n",
      "# explored states: 1907\n",
      "36 LULURUULLLDLURRRRDDLDLRURUULLDLDDLDR\n",
      "1.0 0.8 0.7\n",
      "# iters to converge: 66000\n",
      "# explored states: 2215\n",
      "36 LULURUULLLDLURRRRDDLDLRRUUULLLDDDLDR\n",
      "1.0 0.8 0.8\n",
      "# iters to converge: 25500\n",
      "# explored states: 1476\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLDLDDLDR\n",
      "1.0 0.8 0.9\n",
      "# iters to converge: 30000\n",
      "# explored states: 1663\n",
      "36 ULLURUULLLDLURRRRDDDLLRURUULLLDDDLDR\n",
      "1.0 1.0 0.5\n",
      "# iters to converge: 44800\n",
      "# explored states: 1789\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.6\n",
      "# iters to converge: 14600\n",
      "# explored states: 1323\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.7\n",
      "# iters to converge: 34200\n",
      "# explored states: 1849\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.8\n",
      "# iters to converge: 71900\n",
      "# explored states: 2250\n",
      "22 LULLRURUULLLDLURDDDLDR\n",
      "1.0 1.0 0.9\n",
      "# iters to converge: 42700\n",
      "# explored states: 1890\n",
      "22 LULLRURUULLLDLURDDDLDR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mx/yb710wvs5g99pv88g5f37t2r0000gn/T/ipykernel_17276/2299306173.py:41: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(['']+list(x_range))\n",
      "/var/folders/mx/yb710wvs5g99pv88g5f37t2r0000gn/T/ipykernel_17276/2299306173.py:42: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(['']+list(y_range))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_name = 'sokoban01.txt'\n",
    "t_performance, opt_a, opt_g, opt_eps_d = parameter_tuning(file_name=file_name)\n",
    "visualize_param_tuning('sokoban01.txt',t_performance[0],'eps_decay rate',np.median(opt_eps_d))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
